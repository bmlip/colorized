{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intelligent Agents and Active Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Introduction to Active Inference and application to the design of synthetic intelligent agents \n",
    "- Materials        \n",
    "  - Mandatory\n",
    "    - These lecture notes\n",
    "    - Karl Friston - 2016 - [The Free Energy Principle](https://www.youtube.com/watch?v=NIu_dJGyIQI) (video)\n",
    "  - Optional\n",
    "    - Raviv (2018), [The Genius Neuroscientist Who Might Hold the Key to True AI](https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/).\n",
    "        - Interesting article on Karl Friston, who is a leading theoretical neuroscientist working on a theory that relates life and intelligent behavior to physics (and Free Energy minimization). (**highly recommended**) \n",
    "  - References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Illustrative Example\n",
    "\n",
    "<span style=\"color:red\">LET'S DO THE MOUNTAIN CAR TASK HERE (THIJS CODE?) or BATMAN PARKING. ANY SUGGESTIONS? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agents\n",
    "\n",
    "- In the previous lessons we assumed that a data set was given. \n",
    "- In this lesson we consider _agents_. An agent is a system that _interacts_ with its environment through both sensors and actuators.\n",
    "- Crucially, by acting onto the environment, the agent is able to affect the data that it will sense in the future.\n",
    "  - As an example, by changing the direction where I look, I can affect the sensory data that will be sensed by my retina.\n",
    "- With this definition of an agent, (biological) organisms are agents, and so are robots, self-driving cars, etc.\n",
    "- In an engineering context, we are particularly interesting in agents that behave with purpose (with a goal in mind), e.g. to drive a car or to design a speech recognition algorithm.\n",
    "- In this lesson, we will describe how __goal-directed behavior__ by biological (and synthetic) agents can also be interpreted as minimization of a free energy functional $F[q]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation: Karl Friston on the Cost Function for Behavior\n",
    "\n",
    "- Have a look at this [video segment by Karl Friston on the cost function for intelligent behavior](https://www.vibby.com/watch?vib=71iPtUJxd).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What makes a good agent?\n",
    "\n",
    "<img src=\"./figures/good-regulator.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agent vs environment interaction\n",
    "\n",
    "<img src=\"./figures/agent-environment-interaction.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### System architecture \n",
    "\n",
    "- An active inference-based agent comprises of\n",
    "  1. A free energy functional $F[q] = \\mathbb{E}_q\\left[ \\log\\frac{q(z)}{p(x,z)}\\right]$, where\n",
    "    - $p(x,z) = \\prod_k p(x_k,z_k|z_{k-1})$ with (latent) $z_k = \\{ s_k, u_k, \\theta_k\\}$ is a _generative_ model.\n",
    "    - $q(z)$ is a _recognition_ model.\n",
    "  2. A recipe to minimize the free energy $F[q]$\n",
    "\n",
    "- We also assume that the agent interacts with an environment, which we represent by a dynamic model\n",
    "$$\n",
    "(y_t,\\tilde{s}_t) = R_t\\left( a_t,\\tilde{s}_{t-1}\\right)\n",
    "$$\n",
    "where $a_t$ are _actions_ , $y_t$ are _outcomes_ and $\\tilde{s}_t$ holds the environmental _states_. \n",
    "\n",
    "- The agent can push actions $a_t$ onto the environment and measure responses $y_t$, but has no access to the environmental states $\\tilde{s}_t$.\n",
    "\n",
    "- Interactions between the agent and environment are described by \n",
    "$$\\begin{align*}\n",
    "a_t &\\sim q(u_t) \\\\\n",
    "x_t &= y_t \n",
    "\\end{align*}$$\n",
    "iow, actions are drawn from the posterior over control signals.\n",
    "\n",
    "- Note that this system implies a recursive dependency since the agent's future observations depend on the agent's current (and past) actions: $$x_{t+1} = x_{t+1} \\left( a_{t+1} \\right) = x_{t+1} \\left( a_{t+1} \\left( u_{t+1}\\left( x_t \\left( a_t \\left( \\cdots \\right) \\right) \\right)\\right) \\right)$$\n",
    "  - The agent selects its own data set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Biological interpretation\n",
    "- In biotic parlance, \n",
    "  - _behavior_ is inference for the control signals ($u$)\n",
    "  - _perception_ is inference for the internal states ($s$). \n",
    "  - _learning_ is inference for the parameters ($\\theta$)\n",
    " \n",
    "- The CA decomposition of free energy shows that _actions_ aim to maximize accuracy since complexity is not a function of the data ($x = x(a)$) \n",
    "$$ F[q]=  \\underbrace{\\sum_z q(z)\\log\\frac{q(z)}{p(z)}}_{\\text{complexity}} - \\underbrace{\\sum_z q(z) \\log p(x|z)}_{\\text{accuracy}}$$\n",
    "\n",
    "- The DE decomposition reveals that _perception_ minimizes inference costs since log-evidence is not affected by inference (not a function of $q$)\n",
    "$$F[q] = \\underbrace{\\sum_z q(z) \\log \\frac{q(z)}{p(z|x)}}_{\\text{divergence}} - \\underbrace{\\log p(x)}_{\\text{log-evidence}}$$\n",
    "\n",
    "- Finally, the EE decomposition discloses a deep link with the 2nd law of thermodynamics (drive towards maximum entropy). An agent aims to maximize entropy over its beliefs subject to constraints put up by its generative model and inference skills (the energy term)\n",
    "$$F[q] = \\underbrace{-\\sum_z q(z) \\log p(x,z)}_{\\text{energy}} - \\underbrace{\\sum_z q(z) \\log \\frac{1}{q(z)}}_{\\text{entropy}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model specification\n",
    "\n",
    "- We assume that agents live in a dynamic environment and consider the following generative model for the agent (omitting parameters $\\theta$)\n",
    "$$\\begin{align*}\n",
    "p^\\prime(x,s,u) &= p(s_{t-1}) \\prod_{k=t}^{t+T} \\underbrace{p(x_k|s_k) \\cdot p(s_k | s_{k-1}, u_k)}_{\\text{internal dynamics}} \\cdot\\underbrace{p(u_k)}_{\\substack{\\text{control prior}}}\n",
    "\\end{align*}$$\n",
    "\n",
    "- In order to infer _goal-driven_ (i.e., purposeful) behavior, we now add prior beliefs $p^+(x)$ about future outcomes, leading to an extended agent model:\n",
    "$$\\begin{align*}\n",
    "p(x,s,u) &= \\frac{p^\\prime(x,s,u) p^+(x)}{\\int_x p^\\prime(x,s,u) p^+(x) \\mathrm{d}x} \\\\\n",
    "  &\\propto p(s_{t-1}) \\prod_{k=t}^{t+T} p(x_k|s_k) p(s_k | s_{k-1}, u_k) p(u_k) p^+(x_k)\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FFG for Agent Model\n",
    "\n",
    "- After selecting an action $a_t$ and making an observation $y_t$, the FFG for the model is given by the following FFG:\n",
    "\n",
    "<img src=\"./figures/fig-active-inference-model-specification.png\" width=\"800px\">\n",
    "\n",
    "- The (brown) dashed box is the agent's Markov blanket.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Online Active Inference\n",
    "\n",
    "- Online active inference proceeds by iteratively executing three stages: (1) act-execute-observe, (2) infer, (3) slide forward\n",
    "\n",
    "<img src=\"./figures/fig-online-active-inference.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specification of Free Energy \n",
    "\n",
    "- Consider the agent's inference task at time step $t$, right after having selected an action $a_t$ and having made an observation $y_t$.\n",
    "\n",
    "- As usual, we record actions and observations by substituting the values into the generative model(in the Act-Execute-Observe phase):\n",
    "$$\\begin{align*}\n",
    "p(x,s,u) &\\propto  \\underbrace{p(x_t=y_t|s_t)}_{\\text{observation}} p(s_t|s_{t-1},u_t) p(s_{t-1}) \\underbrace{p(u_t=a_t)}_{\\text{action}} \\\\ & \\quad \\cdot \\underbrace{\\prod_{k=t+1}^{t+T} p(x_k|s_k) p(s_k | s_{k-1}, u_k) p(u_k) p^+(x_k)}_{\\text{future}}\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "- Note that (future) $x$ is also a latent variable and hence we include $x$ in the recognition model.  \n",
    "\n",
    "- This leads to the following free energy functional\n",
    "$$\\begin{align*}\n",
    "F[q] &\\propto \\sum_{x,s,u} q(x,s,u) \\log \\frac{q(x,s,u)}{p(x,s,u)} \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FE Decompositions \n",
    "\n",
    "- Lots of interesting FE decompositions are possible again. For instance\n",
    "$$\\begin{align*}\n",
    "F[q] &\\propto \\sum_{x,s,u} q(x,s,u) \\log \\frac{q(x,s,u)}{p(x,s,u)} \\\\\n",
    "&= \\sum_{u} q(u) \\underbrace{\\sum_{x,s} q(x,s|u)\\log \\frac{q(x,s|u)}{p(x,s|u)}}_{F_u[q]} + \\underbrace{\\sum_{u} q(u) \\log \\frac{q(u)}{p(u)}}_{\\text{complexity}}\n",
    "\\end{align*}$$\n",
    "breaks the FE into a complexity term and a term $F_u[q]$ that is conditioned on the policy $u$. \n",
    "\n",
    "- It can be shown (exercise) that the optimal posterior for the policy is now given by\n",
    "$$\n",
    "q^*(u) \\propto p(u) \\exp \\left( -F^*_u \\right)\n",
    "$$\n",
    "\n",
    "- Let's consider a break-up $x=(x_t,x_{>t})$ with $x_{>t} = (x_{t+1},\\ldots,x_{t+T})$ that recognizes the distinction between already observed and future data. Then\n",
    "$$\\begin{align*}\n",
    "F_u[q] &= \\underbrace{-\\log p(x_t)}_{\\substack{-\\log(\\text{evidence})  \\\\ \\text{(surprise)}}} + \\underbrace{\\sum_{x,s} q(x_{>t},s|u)\\log \\frac{q(x_{>t},s|u)}{p(x_{>t},s|u)}}_{\\substack{\\text{divergence}\\\\ \\text{(inference costs)}}}\\,.\n",
    "\\end{align*}$$\n",
    "\n",
    "- The inference costs (divergence term) can be further decomposed to \n",
    "$$\\begin{align*} \\underbrace{-\\sum_{x} q(x_{>t}) \\log p(x_{>t})}_{\\substack{\\text{expected surprise}  \\\\ \\text{(goal-directed, pragmatic costs)}}} + \\underbrace{\\sum_{x,s} q(x_{>t},s|u) \\log \\frac{q(x_{>t},s|u)}{p(s|x_{>t},u)}}_{\\text{epistemic costs}}\n",
    "\\end{align*}$$\n",
    "\n",
    "- Minimizing goal-directed costs selects actions that (expect to) fullfil the priors over future observations. Minimization of epistemic (\"knowledge seeking\") costs leads to actions that maximize information gain about the environmental dynamics. This can be seen by further decomposition of the epistemic costs into\n",
    "$$\\begin{align*}\n",
    "&\\sum_{x,s} q(x_>t,s|u) \\log \\frac{q(s|u)}{p(s|x_{>t},u)} + \\sum_{x,s} q(x_{>t},s|u) \\log q(x_{>t}|s,u) \\\\\n",
    "\\approx &\\underbrace{\\sum_{x,s} q(x_>t,s|u) \\log \\frac{q(s|u)}{q(s|x_{>t},u)}}_{-\\text{mutual information}} - \\underbrace{\\mathbb{E}_{q(s|u)}\\left[ H\\left[ q(x_{>t}|s,u)\\right]\\right]}_{\\text{ambiguity}} \n",
    "\\end{align*}$$\n",
    "where we used the approximation $q(s|x_{>t},u) \\approx p(s|x_{>t},u)$ to illuminate the link to the mutual information. \n",
    "\n",
    "- <font color=\"red\">this seems to be a problem since we want to minimize ambiguity. Check this further </font>\n",
    "\n",
    "- Minimizing FE leads (approximately) to mutual information maximization between internal states $s$ and observations $x$. In other words, FEM leads to actions that aim to seek out observations that are maximally informative about the hidden causes of these observations. \n",
    "\n",
    "- Ambiguous states have uncertain mappings to observations. Minimizing FE leads to actions that try to avoid ambiguous states. \n",
    "\n",
    "- In short, if the generative model includes variables that represent (yet) unobserved future observations, then action selection by FEM leads to a very sophisticated behavioral strategy that is maximally consistent with  \n",
    "  - Bayesian notions of model complexity\n",
    "  - evidence from past observations\n",
    "  - goal-directed imperatives by priors on future observations\n",
    "  - epistemic (knowledge seeking) value maximization, both in terms of MI maximization and avoidance of ambiguous states\n",
    "  \n",
    "- All these imperatives are simultaneously represented and automatically balanced against each other in a single time-varying cost function (Free Energy) that needs no tuning parameters. \n",
    "\n",
    "- (Just to be sure, you don't need to memorize these derivations nor are you expected to derive them on-the-spot. We present these decompositions only to provide insight into the multitude of forces that underlie FEM-based action selection.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Free energy distribution in FFG \n",
    "\n",
    "(obsolete now, needs update)\n",
    "\n",
    "<img src=\"./figures/ffg-active-inference-for-policy.png\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \n",
    "\n",
    "[Friston at CCN-2016 on Active Inference Applications](https://www.vibby.com/v/Q1Vir9QKGd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\n",
       "This HTML file contains custom styles and some javascript.\n",
       "Include it a Jupyter notebook for improved rendering.\n",
       "-->\n",
       "\n",
       "<!-- Fonts -->\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<!-- Custom style -->\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: rgb(245,245,245);\n",
       "}\n",
       "\n",
       "div.container {\n",
       "    min-width: 960px;\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    margin: auto;\n",
       "    padding-left: 0em;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "    margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running {\n",
       "    border: 1px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\n",
       "div.cell.code_cell {\n",
       "    background-color: rgb(256,256,256);\n",
       "    border-radius: 0px;\n",
       "    padding: 0.5em;\n",
       "    margin-left:1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Alegreya Sans' sans-serif;\n",
       "    line-height: 140%;\n",
       "    font-size: 125%;\n",
       "    font-weight: 400;\n",
       "    width:800px;\n",
       "    margin-left:auto;\n",
       "    margin-right:auto;\n",
       "}\n",
       "\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-style:regular;\n",
       "    font-weight: 400;\n",
       "    font-size: 45pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.3em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    margin-top:16px;\n",
       "    font-size: 22pt;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: regular;\n",
       "    color: rgb(102,102,0);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {    /*Use this for captions*/\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-size: 14pt;\n",
       "    text-align: center;\n",
       "    margin-top: 0em;\n",
       "    margin-bottom: 2em;\n",
       "    font-style: regular;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\n",
       "    font-family: 'Nixie One', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 16pt;\n",
       "    color: rgb(163,0,0);\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.8em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 { /*use this for copyright note*/\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 9pt;\n",
       "    line-height: 100%;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 90%;\n",
       "}\n",
       "\n",
       ".boxed { /* draw a border around a piece of text */\n",
       "  border: 1px solid blue ;\n",
       "}\n",
       "\n",
       "h4#CODE-EXAMPLE,\n",
       "h4#END-OF-CODE-EXAMPLE {\n",
       "    margin: 10px 0;\n",
       "    padding: 10px;\n",
       "    background-color: #d0f9ca !important;\n",
       "    border-top: #849f81 1px solid;\n",
       "    border-bottom: #849f81 1px solid;\n",
       "}\n",
       "\n",
       ".emphasis {\n",
       "    color: red;\n",
       "}\n",
       "\n",
       ".exercise {\n",
       "    color: green;\n",
       "}\n",
       "\n",
       ".proof {\n",
       "    color: blue;\n",
       "}\n",
       "\n",
       "code {\n",
       "  padding: 2px 4px !important;\n",
       "  font-size: 90% !important;\n",
       "  color: #222 !important;\n",
       "  background-color: #efefef !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\n",
       "   as they will be removed through some other method */\n",
       "@media not print {\n",
       "  .cell:nth-last-child(-n+2) {\n",
       "    display: none;\n",
       "  }\n",
       "}\n",
       "\n",
       "footer.hidden-print {\n",
       "    display: none !important;\n",
       "}\n",
       "    \n",
       "</style>\n",
       "\n",
       "<!-- MathJax styling -->\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"],\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f\n",
    "    display(\"text/html\", read(f,String))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
