{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intelligent Agents and Active Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Introduction to Active Inference and application to the design of synthetic intelligent agents \n",
    "- Materials        \n",
    "  - Mandatory\n",
    "    - These lecture notes\n",
    "    - Karl Friston - 2016 - [The Free Energy Principle](https://www.youtube.com/watch?v=NIu_dJGyIQI) (video)\n",
    "  - Optional\n",
    "  - References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Illustrative Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agents\n",
    "\n",
    "- In the previous lessons we assumed that a data set was given. \n",
    "- In this lesson we consider _agents_. An agent is a system that _interacts_ with its environment through both sensors and actuators.\n",
    "- Crucially, by acting onto the environment, the agent is able to affect the data that it will sense in the future.\n",
    "  - As an example, by changing the direction where I look, I can affect the sensory data that will be sensed by my retina.\n",
    "- With this definition of an agent, (biological) organisms are agents, and so are robots, self-driving cars, etc.\n",
    "- In an engineering context, we are particularly interesting in agents that behave with purpose (with a goal in mind), e.g. to drive a car or to design a speech recognition algorithm.\n",
    "- In this lesson, we will describe how __goal-directed behavior__ by biological (and synthetic) agents can also be interpreted as minimization of a free energy functional $F[q]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Friston at CCN-2016 2 fragments\n",
    "\n",
    "https://vib.by/v/71iPtUJxd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://youtu.be/b1hEc6vay_k?start=254&end=475\n",
    "\n",
    "https://youtu.be/b1hEc6vay_k?t=4505&end4860\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What makes a good agent?\n",
    "\n",
    "<img src=\"./figures/good-regulator.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agent vs environment interaction\n",
    "\n",
    "<img src=\"./figures/agent-environment-interaction.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### System architecture \n",
    "\n",
    "- An agent comprises of\n",
    "  1. a generative model $p(x|z) p(z)$, where $z = \\{ s, u, \\theta\\}$.\n",
    "  2. a recognition model $q(z)$\n",
    "  3. a recipe to minimize FE $F[q]$\n",
    "\n",
    "- We also assume that the agent interacts with an environment, which we represent by a dynamic model\n",
    "$$\n",
    "(y_t,\\tilde{s}_t) = R_t\\left( a_t,\\tilde{s}_{t-1}\\right)\n",
    "$$\n",
    "where $a_t$ are _actions_ , $y_t$ are _outcomes_ and $\\tilde{s}_t$ holds the environmental _states_. \n",
    "\n",
    "- The agent can push actions $a_t$ onto the environment and measure responses $y_t$, but has no access to the environmental states $\\tilde{s}_t$.\n",
    "\n",
    "- Interactions between the agent and environment are described by \n",
    "$$\\begin{align*}\n",
    "a_t &\\sim q(u_t) \\\\\n",
    "x_t &= y_t \n",
    "\\end{align*}$$\n",
    "iow, actions are drawn from the posterior over control signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Biological interpretation\n",
    "- Biologically, \n",
    "  - _actions_ onto the environment follow from inference for control signals ($u$)\n",
    "  - _perception_ is inference for the internal states ($s$). \n",
    "  - _learning_ relates to inference for the parameters ($\\theta$)\n",
    "  \n",
    "- The CA decomposition of free energy shows that _actions_ aim to maximize accuracy since complexity is not a function of the data ($x$) \n",
    "$$ F[q]=  \\underbrace{\\sum_z q(z)\\log\\frac{q(z)}{p(z)}}_{\\text{complexity}} - \\underbrace{\\sum_z q(z) \\log p(x|z)}_{\\text{accuracy}}$$\n",
    "\n",
    "- The DE decomposition reveals that _perception_ minimizes inference costs since log-evidence is not affected by inference (not a function of $q$)\n",
    "$$F[q] = \\underbrace{\\sum_z q(z) \\log \\frac{q(z)}{p(z|x)}}_{\\text{divergence}} - \\underbrace{\\log p(x)}_{\\text{log-evidence}}$$\n",
    "\n",
    "- Finally, the EE decomposition discloses a deep link with the 2nd law of thermodynamics (drive towards maximum entropy). Agents aims to maximize entropy subject to constraints put up by its generative model and inference skills (the energy term)\n",
    "$$F[q] = \\underbrace{-\\sum_z q(z) \\log p(x,z)}_{\\text{energy}} - \\underbrace{\\sum_z q(z) \\log \\frac{1}{q(z)}}_{\\text{entropy}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model specification\n",
    "\n",
    "- We assume that agents live in a dynamic environment and consider the following generative model for the agent (omitting parameters $\\theta$)\n",
    "$$\\begin{align*}\n",
    "p^\\prime(x,s,u) &= p(s_{t-1}) \\prod_{k=t}^{t+T} \\underbrace{p(x_k|s_k) \\cdot p(s_k | s_{k-1}, u_k)}_{\\text{internal dynamics}} \\cdot\\underbrace{p(u_k)}_{\\substack{\\text{control prior}}}\n",
    "\\end{align*}$$\n",
    "\n",
    "- In order to infer _goal-driven_ (i.e., purposeful) behavior, we now add prior beliefs $p^+(x)$ about future outcomes, leading to an extended agent model:\n",
    "$$\\begin{align*}\n",
    "p(x,s,u) &= \\frac{p^\\prime(x,s,u) p^+(x)}{\\int_x p^\\prime(x,s,u) p^+(x) \\mathrm{d}x} \\\\\n",
    "  &\\propto p(s_{t-1}) \\prod_{k=t}^{t+T} p(x_k|s_k) p(s_k | s_{k-1}, u_k) p(u_k) p^+(x_k)\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FFG for Agent Model\n",
    "\n",
    "- After selecting an action $a_t$ and making an observation $y_t$, the FFG for the model is given by the following FFG:\n",
    "\n",
    "<img src=\"./figures/fig-active-inference-model-specification.png\" width=\"800px\">\n",
    "\n",
    "- The (brown) dashed box is the agent's Markov blanket.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Online Active Inference\n",
    "\n",
    "- Online active inference proceeds by iteratively executing three stages: (1) act-execute-observe, (2) infer, (3) slide forward\n",
    "\n",
    "<img src=\"./figures/fig-online-active-inference.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specification of Free Energy \n",
    "\n",
    "- Consider the agent's inference task at time step $t$, right after having selected an action $a_t$ and having made an observation $y_t$.\n",
    "\n",
    "- As usual, we record actions and observations by substituting the values into the generative model(in the Act-Execute-Observe phase):\n",
    "$$\\begin{align*}\n",
    "p(x,s,u) &\\propto  \\underbrace{p(x_t=y_t|s_t)}_{\\text{observation}} p(s_t|s_{t-1},u_t) p(s_{t-1}) \\underbrace{p(u_t=a_t)}_{\\text{action}} \\\\ & \\quad \\cdot \\underbrace{\\prod_{k=t+1}^{t+T} p(x_k|s_k) p(s_k | s_{k-1}, u_k) p(u_k) p^+(x_k)}_{\\text{future}}\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "- Note that (future) $x$ is also a latent variable and hence we include $x$ in the recognition model.  \n",
    "\n",
    "- This leads to the following free energy functional\n",
    "$$\\begin{align*}\n",
    "F[q] &\\propto \\sum_{x,s,u} q(x,s,u) \\log \\frac{q(x,s,u)}{p(x,s,u)} \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FE Decompositions \n",
    "\n",
    "- Lots of interesting FE decompositions are possible again. For instance\n",
    "$$\\begin{align*}\n",
    "F[q] &= \\sum_{u} q(u) \\underbrace{\\sum_{x,s,u} q(x,s|u)\\log \\frac{q(x,s|u)}{p(x,s|u)}}_{F_u[q]} + \\underbrace{\\sum_{u} q(u) \\log \\frac{q(u)}{p(u)}}_{\\text{complexity}}\n",
    "\\end{align*}$$\n",
    "breaks the FE into a complexity term and a term $F_u[q]$ that is conditioned on the policy $u$. \n",
    "\n",
    "- It can be shown (exercise) that the optimal posterior for the policy is now given by\n",
    "$$\n",
    "q^*(u) \\propto p(u) \\exp \\left( -F^*_u \\right)\n",
    "$$\n",
    "\n",
    "- Let's consider a break-up $x=(x_t,x_{>t})$ with $x_{>t} = (x_{t+1},\\ldots,x_{t+T})$ that recognizes the distinction between already observed and future data (and similarly $s=(s_t,s_{>t})$). Then (see Schwoebel et al 2019, eq.2.15), \n",
    "$$\\begin{align*}\n",
    "F_u[q] &= \\sum_{x,s,u} q(x,s|u)\\log \\left( \\frac{q(s_t|u)}{p(x_t,s_t|u)} \\cdot \\frac{q(x_{>t},s_{>t}|s_t, u)}{p(x_{>t},s_{>t}|s_t,u)} \\right)\\\\\n",
    "&= \\underbrace{\\sum_{s_t} q(s_t|u)\\log \\frac{q(s_t|u)}{p(x_t,s_t|u)}}_{\\text{observed free energy }V_u[q]} +  \\underbrace{\\sum_{x_{>t},s_{>t},s_t} q(x_{>t},s_{>t},s_t|u) \\log \\frac{q(x_{>t},s_{>t}|s_t, u)}{p(x_{>t},s_{>t}|s_t,u)}}_{\\text{predicted free energy }G_u[q]}\n",
    "\\end{align*}$$\n",
    "where the observed free energy relates to FE as a result of observed value $x_t$ and the predicted free energy depends on priors for future observations $x_{>t}$\n",
    "\n",
    "- In particular, using $p(x_{>t},s_{>t}|s_t,u) \\propto p^\\prime(x_{>t},s_{>t}|s_t,u) \\cdot p^+(x_{>t})$, we can further break down the free energies into divergence and evidence terms as\n",
    "$$\\begin{align*}\n",
    "G_u[q] &\\propto \\underbrace{\\sum_{x_{>t},s_{>t},s_t} q(x_{>t},s_{>t},s_t|u) \\log \\frac{q(x_{>t},s_{>t}|s_t, u)}{p^\\prime(x_{>t},s_{>t}|s_t,u)}}_{\\text{inference costs (as KL divergence)}}  - \\underbrace{\\sum_{x_{>t}} q(x_{>t}|u) \\log p^+(x_{>t})}_{\\substack{\\text{goal-directed behavior} \\\\ \\text{(expected log-evidence)}}} \\\\\n",
    "V_u[q] &= \\underbrace{\\sum_{s_t} q(s_t|u)\\log \\frac{q(s_t|u)}{p(s_t|,x_t,u)}}_{\\text{inference costs}} - \\underbrace{\\log p(x_t)}_{\\text{log-evidence}} \n",
    "\\end{align*}$$\n",
    "\n",
    "- Thus, minimizing FE $F_u[q]$ leads to a policy $u$ that is driven by a goal-directed term. Inaccuracies in the policy are due to inference costs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\r\n",
       "This HTML file contains custom styles and some javascript.\r\n",
       "Include it a Jupyter notebook for improved rendering.\r\n",
       "-->\r\n",
       "\r\n",
       "<!-- Fonts -->\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\r\n",
       "\r\n",
       "<!-- Custom style -->\r\n",
       "<style>\r\n",
       "\r\n",
       "@font-face {\r\n",
       "    font-family: \"Computer Modern\";\r\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\r\n",
       "}\r\n",
       "\r\n",
       "#notebook_panel { /* main background */\r\n",
       "    background: rgb(245,245,245);\r\n",
       "}\r\n",
       "\r\n",
       "div.container {\r\n",
       "    min-width: 960px;\r\n",
       "}\r\n",
       "\r\n",
       "div #notebook { /* centre the content */\r\n",
       "    background: #fff; /* white background for content */\r\n",
       "    margin: auto;\r\n",
       "    padding-left: 0em;\r\n",
       "}\r\n",
       "\r\n",
       "#notebook li { /* More space between bullet points */\r\n",
       "    margin-top:0.8em;\r\n",
       "}\r\n",
       "\r\n",
       "/* draw border around running cells */\r\n",
       "div.cell.border-box-sizing.code_cell.running {\r\n",
       "    border: 1px solid #111;\r\n",
       "}\r\n",
       "\r\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\r\n",
       "div.cell.code_cell {\r\n",
       "    background-color: rgb(256,256,256);\r\n",
       "    border-radius: 0px;\r\n",
       "    padding: 0.5em;\r\n",
       "    margin-left:1em;\r\n",
       "    margin-top: 1em;\r\n",
       "}\r\n",
       "\r\n",
       "div.text_cell_render{\r\n",
       "    font-family: 'Alegreya Sans' sans-serif;\r\n",
       "    line-height: 140%;\r\n",
       "    font-size: 125%;\r\n",
       "    font-weight: 400;\r\n",
       "    width:800px;\r\n",
       "    margin-left:auto;\r\n",
       "    margin-right:auto;\r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "/* Formatting for header cells */\r\n",
       ".text_cell_render h1 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-style:regular;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 45pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0,51,102);\r\n",
       "    margin-bottom: 0.5em;\r\n",
       "    margin-top: 0.5em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h2 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 30pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0,51,102);\r\n",
       "    margin-bottom: 0.1em;\r\n",
       "    margin-top: 0.3em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h3 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    margin-top:16px;\r\n",
       "    font-size: 22pt;\r\n",
       "    font-weight: 600;\r\n",
       "    margin-bottom: 3px;\r\n",
       "    font-style: regular;\r\n",
       "    color: rgb(102,102,0);\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h4 {    /*Use this for captions*/\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-size: 14pt;\r\n",
       "    text-align: center;\r\n",
       "    margin-top: 0em;\r\n",
       "    margin-bottom: 2em;\r\n",
       "    font-style: regular;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\r\n",
       "    font-family: 'Nixie One', sans-serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 16pt;\r\n",
       "    color: rgb(163,0,0);\r\n",
       "    font-style: italic;\r\n",
       "    margin-bottom: .1em;\r\n",
       "    margin-top: 0.8em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h6 { /*use this for copyright note*/\r\n",
       "    font-family: 'PT Mono', sans-serif;\r\n",
       "    font-weight: 300;\r\n",
       "    font-size: 9pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: grey;\r\n",
       "    margin-bottom: 1px;\r\n",
       "    margin-top: 1px;\r\n",
       "}\r\n",
       "\r\n",
       ".CodeMirror{\r\n",
       "    font-family: \"PT Mono\";\r\n",
       "    font-size: 90%;\r\n",
       "}\r\n",
       "\r\n",
       ".boxed { /* draw a border around a piece of text */\r\n",
       "  border: 1px solid blue ;\r\n",
       "}\r\n",
       "\r\n",
       "h4#CODE-EXAMPLE,\r\n",
       "h4#END-OF-CODE-EXAMPLE {\r\n",
       "    margin: 10px 0;\r\n",
       "    padding: 10px;\r\n",
       "    background-color: #d0f9ca !important;\r\n",
       "    border-top: #849f81 1px solid;\r\n",
       "    border-bottom: #849f81 1px solid;\r\n",
       "}\r\n",
       "\r\n",
       ".emphasis {\r\n",
       "    color: red;\r\n",
       "}\r\n",
       "\r\n",
       ".exercise {\r\n",
       "    color: green;\r\n",
       "}\r\n",
       "\r\n",
       ".proof {\r\n",
       "    color: blue;\r\n",
       "}\r\n",
       "\r\n",
       "code {\r\n",
       "  padding: 2px 4px !important;\r\n",
       "  font-size: 90% !important;\r\n",
       "  color: #222 !important;\r\n",
       "  background-color: #efefef !important;\r\n",
       "  border-radius: 2px !important;\r\n",
       "}\r\n",
       "\r\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\r\n",
       "   as they will be removed through some other method */\r\n",
       "@media not print {\r\n",
       "  .cell:nth-last-child(-n+2) {\r\n",
       "    display: none;\r\n",
       "  }\r\n",
       "}\r\n",
       "\r\n",
       "footer.hidden-print {\r\n",
       "    display: none !important;\r\n",
       "}\r\n",
       "    \r\n",
       "</style>\r\n",
       "\r\n",
       "<!-- MathJax styling -->\r\n",
       "<script>\r\n",
       "    MathJax.Hub.Config({\r\n",
       "                        TeX: {\r\n",
       "                           extensions: [\"AMSmath.js\"],\r\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\r\n",
       "                           },\r\n",
       "                tex2jax: {\r\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\r\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\r\n",
       "                },\r\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\r\n",
       "                \"HTML-CSS\": {\r\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\r\n",
       "                }\r\n",
       "        });\r\n",
       "</script>\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f\n",
    "    display(\"text/html\", read(f,String))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
