{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probabilistic Programming 4: Particle filter\n",
    "## Monte Carlo sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Learn to apply Turing to a dynamical system.\n",
    "- Materials        \n",
    "  - Mandatory\n",
    "    - These lecture notes.    \n",
    "  - Optional\n",
    "      - [Probabilistic Programming notebook](https://github.com/bertdv/BMLIP/tree/master/lessons/notebooks/probprog/Probabilistic-Programming.ipynb)\n",
    "      - David Blei (https://doi.org/10.1146/annurev-statistics-022513-115657)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package managing\n",
    "using Pkg\n",
    "Pkg.activate(\"workspace\")\n",
    "Pkg.instantiate();\n",
    "\n",
    "using Logging; disable_logging(LogLevel(0))\n",
    "using Distributions\n",
    "using StatsPlots\n",
    "using Turing\n",
    "using MCMCChains\n",
    "Turing.setadbackend(:forward_diff)\n",
    "include(\"../scripts/pp-4.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "\n",
    "In this notebook, we will be considering continuous state-space models. We will focus on the simplest form: the Gaussian dynamical system:\n",
    "\n",
    "$$\\begin{align}\n",
    "x_k =&\\ A_kx_{k-1} + q_{k-1} \\\\\n",
    "y_k =&\\ H_kx_k + r_k \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "where $x_k \\in \\mathbb{R}^{N}$ is the state, $y_k \\in \\mathbb{R}^{M}$ is the measurement. Process noise and measurement noise are assumed to be zero mean Gaussian with covariance matrices $Q_k$ and $R_k$ respectively. In Bayesian notation this takes the form:\n",
    "\n",
    "$$\\begin{align}\n",
    "p(x_k \\mid x_{k-1}) =&\\ \\mathcal{N}(x_k \\mid A_k x_{k-1}, Q_{k-1})\\\\\n",
    "p(y_k \\mid x_k) =&\\ \\mathcal{N}(y_k \\mid H_k x_k, R_k) \\, .\n",
    "\\end{align}$$\n",
    "\n",
    "We can sample from these distributions to generate data. We'll consider a $2$-dimensional state (i.e. $N=2$) and a $2$-dimensional observation (i.e. $M=2$). First, we set the initial state $x_0$ to some value and generate $x_1$ through the state transition. Then, we generate the observation $y_1$ from the generated state $x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionalities\n",
    "N = 2\n",
    "M = 2\n",
    "\n",
    "# Length of time-series\n",
    "T = 50\n",
    "\n",
    "# Lenght of time step\n",
    "Δt = 1.0\n",
    "\n",
    "# Transition matrix of latent variables\n",
    "transition = [1.0 Δt;\n",
    "              0.0 1.0]\n",
    "\n",
    "# Emission matrix for observed variables\n",
    "emission = [1.0 0.;0. 1.0]\n",
    "\n",
    "# Process noise (latent variables)\n",
    "process_noise = [0.2*Δt 0.;0. 0.1*Δt]\n",
    "\n",
    "# Measurement noise (observations)\n",
    "measurement_noise = [0.1 0.;0. 0.1]\n",
    "\n",
    "# Preallocate data arrays\n",
    "states = zeros(2,T)\n",
    "observations = zeros(2,T)\n",
    "\n",
    "# Initial state\n",
    "state_0 = [0., 0.]\n",
    "\n",
    "# Keep previous state in memory\n",
    "state_tmin = state_0\n",
    "\n",
    "# Generate data for entire time-series\n",
    "for t = 1:T\n",
    "    \n",
    "    # Transition from previous state\n",
    "    states[:,t] = rand(MvNormal(transition * state_tmin, process_noise), 1)[:,1]\n",
    "    \n",
    "    # Emission of current state\n",
    "    observations[:,t] = rand(MvNormal(emission * states[:,t], measurement_noise), 1)[:,1]\n",
    "    \n",
    "    # Update previous state\n",
    "    state_tmin = states[:,t]\n",
    "    \n",
    "end\n",
    "\n",
    "# Visualization of states\n",
    "plot(states[1,:], states[2,:], color=\"red\", label=\"states\", grid=false, xlabel=\"position x-coordinate\", ylabel=\"position y-coordinate\")\n",
    "scatter!(observations[1,:], observations[2,:], color=\"blue\", label=\"observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have a time-axis anymore, it is hard to see how the process evolves. Animating the path resolves this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation of cart's path\n",
    "\n",
    "# Plot initial state\n",
    "plot([states[1,1]], [states[2,1]], \n",
    "     color=\"red\", \n",
    "     label=\"states\", \n",
    "     grid=false, \n",
    "     xlabel=\"position x-coordinate\", \n",
    "     ylabel=\"position y-coordinate\", \n",
    "     xlims=[-60,60], \n",
    "     ylims=[-10,10])\n",
    "\n",
    "# Plot initial observation\n",
    "scatter!([observations[1,1]], [observations[2,1]], color=\"blue\", label=\"observations\")\n",
    "\n",
    "anim = @animate for t = 2:T\n",
    "    \n",
    "    title!(\"t = \"*string(t))\n",
    "    \n",
    "    # Plot new state\n",
    "    plot!([states[1,t-1:t]], [states[2,t-1:t]], color=\"red\", label=\"\")\n",
    "    \n",
    "    # Plot new observation\n",
    "    scatter!([observations[1,t]], [observations[2,t]], color=\"blue\", label=\"\")\n",
    "    \n",
    "end\n",
    "\n",
    "gif(anim, \"visualizations/example-GDS.gif\", fps = 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specification\n",
    "\n",
    "We will employ a Particle Filter to estimate states and unknown parameters. Particle filters are the basic means of doing Markov Chain Monte Carlo sampling in continous state-space models. They are also known as _Sequential Importance Sampling_ or _Sequential Monte Carlo_ methods. Particle filters essentially sample from the state transition, taking the sample average as the expected new state, and sample from the observation emission, taking the sample average as the expected observation. It will update the expected step in the same way as the Kalman filter: by multiplying the prediction and corrections:\n",
    "\n",
    "$$ \\hat{p}(x_t \\mid y_{1:T}) \\approx \\hat{p}(x_t \\mid x_{t-1}) \\hat{p}(y_t \\mid x_t) \\, ,$$\n",
    "\n",
    "where $\\hat{\\cdot}$ indicates that these distributions are approximated. Particle filters can be applied to non-Gaussian dynamical sytems. In that case, the probabilities of the samples draw from an approximating distribution (e.g. Gaussian) are importance-weighted to resemble the probability distribution of the non-Gaussian dynamical system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we start simple and slowly improve the model.\n",
    "\n",
    "### Model 1: estimate states\n",
    "\n",
    "We will first assume we know the transition and emission matrices. Based on these, we purely want to estimate states from observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turing model definition.\n",
    "@model PF(y, transition, process_noise, emission, measurement_noise) = begin\n",
    "    \"This model implicitly assumes 2-dim states and 2-dim observations\"\n",
    "    \n",
    "    # Time-series length\n",
    "    T = size(y, 2)\n",
    "\n",
    "    # State sequence.\n",
    "    x = Vector{Vector}(undef, T)\n",
    "\n",
    "    # Define initial state\n",
    "    x_0 ~ MvNormal([0., 0.], [1. 0.;0. 1.])\n",
    "    \n",
    "    # Initialize previous state\n",
    "    x_tmin = x_0\n",
    "\n",
    "    # Loop over entire sequence\n",
    "    for t = 1:T\n",
    "        \n",
    "        # State transition     \n",
    "        x[t] ~ MvNormal(transition * x_tmin, process_noise)\n",
    "        \n",
    "        # Observation emission\n",
    "        y[:,t] ~ MvNormal(emission * x[t], measurement_noise)\n",
    "        \n",
    "        # Update previous state\n",
    "        x_tmin = x[t]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Call instance of the model\n",
    "model1 = PF(observations, transition, process_noise, emission, measurement_noise);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a \"Sequential Monte Carlo\" sampler, specifying its number of particles as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of chain\n",
    "len_chain = 200\n",
    "\n",
    "# Define sampler\n",
    "sampler1 = Gibbs(PG(100, :x))\n",
    "\n",
    "# Call sampler\n",
    "chain1 = sample(model1, sampler1, len_chain);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1[:x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the inferred states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of the chain\n",
    "x_hat = reshape(mean(chain1[:x].value.data, dims=[1]), (2,50))\n",
    "\n",
    "# Extract standard error of the mean\n",
    "x_sem = reshape(std(chain1[:x].value.data, dims=[1]), (2,50))\n",
    "x_sem[1,:] ./= sqrt.(range(1, stop=T))\n",
    "x_sem[2,:] ./= sqrt.(range(1, stop=T));\n",
    "\n",
    "# Visualization\n",
    "plot(states[1,:], states[2,:], color=\"red\", label=\"states\", grid=false)\n",
    "plot!(x_hat[1,:], x_hat[2,:], ribbon=[x_sem, x_sem], fillalpha=0.2, color=\"green\", label=\"inferred\")\n",
    "scatter!(observations[1,:], observations[2,:], color=\"blue\", label=\"observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: transition matrix estimation\n",
    "\n",
    "At the moment, we assume we know how the states evolve over time. This is not an unreasonable assumption; in protein folding we know exactly _how_ the protein changes state, i.e. through the signaling of another molecule, and we know the concentration of signal molecules. However, in other applications we do not necessarily know the transition matrix. \n",
    "\n",
    "We can estimate the transition matrix by letting the coefficients be latent variables and posing a prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia-1.3 1.3.1",
   "language": "julia",
   "name": "julia-1.3-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
