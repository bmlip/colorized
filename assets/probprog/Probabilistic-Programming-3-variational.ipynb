{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Programming - 3\n",
    "## Variational inference\n",
    "\n",
    "In this notebook, we are looking at inference in a dynamical system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Learn to apply ForneyLab to a dynamical system.\n",
    "- Materials        \n",
    "  - Mandatory\n",
    "    - These lecture notes.\n",
    "  - Optional\n",
    "    - Cheatsheets: [how does Julia differ from Matlab / Python](https://docs.julialang.org/en/v1/manual/noteworthy-differences/index.html).\n",
    "    - Getting started with [ForneyLab](https://biaslab.github.io/forneylab/docs/getting-started/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/Documents/biaslab/repos/BMLIP/lessons/notebooks/probprog/workspace/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;Pkg.activate(\"workspace\");Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using Distributions\n",
    "using Plots\n",
    "pyplot()\n",
    "include(\"../scripts/pp-3.jl\") \n",
    "\n",
    "Random.seed!(1234);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3 possible states and each variable is in one of those (one-hot encoding)\n",
    "K = 3\n",
    "\n",
    "# Length of time-series\n",
    "T = 50\n",
    "\n",
    "# Transition matrix of latent variables\n",
    "transition = [0.3 0.6 0.1; \n",
    "              0.5 0.2 0.3; \n",
    "              0.2 0.8 0.1]\n",
    "\n",
    "# Emission matrix for observed variables\n",
    "emission = [0.7 0.3 0.0; \n",
    "            0.2 0.6 0.2; \n",
    "            0.0 0.3 0.7]\n",
    "\n",
    "# Preallocate data arrays\n",
    "X = zeros(T+1, K)\n",
    "Y = zeros(T, K)\n",
    "\n",
    "# Initial state\n",
    "X[1,:] = [0.0, 1.0, 0.0] \n",
    "\n",
    "# Generate data for entire time-series\n",
    "for t = 2:T\n",
    "    \n",
    "    # Transition from previous state\n",
    "    A = transition * X[t-1,:]\n",
    "    \n",
    "    # Sample from Categorical distribution\n",
    "    X[t,:] = one_hot(rand(Categorical(A ./ sum(A)), 1)[1], K)\n",
    "    \n",
    "    # Emission of current state\n",
    "    B = emission * X[t,:]\n",
    "    \n",
    "    # Sample from Categorical distribution\n",
    "    Y[t-1,:] = one_hot(rand(Categorical(B ./ sum(B)), 1)[1], K)\n",
    "    \n",
    "end\n",
    "\n",
    "# For visualization, we collapse the data from a one-hot to a numerical encoding\n",
    "states = argmax.(eachrow(X))\n",
    "observations = argmax.(eachrow(Y))\n",
    "\n",
    "# Visualization.\n",
    "plot(1:T, states[2:end], color=\"red\", label=\"states\", ylim=(0, 4), grid=false)\n",
    "scatter!(1:T, observations, color=\"blue\", label=\"observations\")\n",
    "xlabel!(\"time (t)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ForneyLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = FactorGraph()\n",
    "\n",
    "@RV A ~ Dirichlet(ones(3,3)) # Vague prior on transition model\n",
    "@RV B ~ Dirichlet([10.0 1.0 1.0; 1.0 10.0 1.0; 1.0 1.0 10.0]) # Stronger prior on observation model\n",
    "@RV s_0 ~ Categorical(1/3*ones(3))\n",
    "\n",
    "s = Vector{Variable}(undef, n_samples) # one-hot coding\n",
    "x = Vector{Variable}(undef, n_samples) # one-hot coding\n",
    "s_t_min = s_0\n",
    "for t = 1:n_samples\n",
    "    @RV s[t] ~ Transition(s_t_min, A)\n",
    "    @RV x[t] ~ Transition(s[t], B)\n",
    "    \n",
    "    s_t_min = s[t]\n",
    "    \n",
    "    placeholder(x[t], :x, index=t, dims=(3,))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recognition factorization\n",
    "q = RecognitionFactorization(A, B, [s_0; s], ids=[:A, :B, :S])\n",
    "\n",
    "# Generate VMP algorithm\n",
    "algo = variationalAlgorithm(q)\n",
    "\n",
    "# Construct variational free energy evaluation code\n",
    "algo_F = freeEnergyAlgorithm(q);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load algorithms\n",
    "eval(Meta.parse(algo))\n",
    "eval(Meta.parse(algo_F))\n",
    "\n",
    "# Initial recognition distributions\n",
    "marginals = Dict{Symbol, ProbabilityDistribution}(\n",
    "    :A => vague(Dirichlet, (3,3)),\n",
    "    :B => vague(Dirichlet, (3,3)))\n",
    "\n",
    "# Initialize data\n",
    "data = Dict(:x => x_data)\n",
    "n_its = 20\n",
    "\n",
    "# Run algorithm\n",
    "F = Vector{Float64}(undef, n_its)\n",
    "for i = 1:n_its\n",
    "    stepS!(data, marginals)\n",
    "    stepB!(data, marginals)\n",
    "    stepA!(data, marginals)\n",
    "\n",
    "    F[i] = freeEnergy(data, marginals)\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "\n",
    "# Plot free energy\n",
    "plot(1:n_its, F, color=\"black\")\n",
    "\n",
    "grid(\"on\")\n",
    "xlabel(\"Iteration\")\n",
    "ylabel(\"Free Energy\")\n",
    "xlim(0,n_its);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,5))\n",
    "\n",
    "# Collect state estimates\n",
    "x_obs = [findfirst(x_i.==1.0) for x_i in x_data]\n",
    "s_true = [findfirst(s_i.==1.0) for s_i in s_data]\n",
    "\n",
    "# Plot simulated state trajectory and observations\n",
    "subplot(121)\n",
    "plot(1:n_samples, x_obs, \"k*\", label=\"Observations x\", markersize=7)\n",
    "plot(1:n_samples, s_true, \"k--\", label=\"True state s\")\n",
    "yticks([1.0, 2.0, 3.0], [\"Red\", \"Green\", \"Blue\"])\n",
    "grid(\"on\")\n",
    "xlabel(\"Time\")\n",
    "legend(loc=\"upper left\")\n",
    "xlim(0,n_samples)\n",
    "ylim(0.9,3.1)\n",
    "title(\"Data set and true state trajectory\")\n",
    "\n",
    "# Plot inferred state sequence\n",
    "subplot(122)\n",
    "m_s = [mean(marginals[:s_*t]) for t=1:n_samples]\n",
    "m_s_1 = [m_s_t[1] for m_s_t in m_s]\n",
    "m_s_2 = [m_s_t[2] for m_s_t in m_s]\n",
    "m_s_3 = [m_s_t[3] for m_s_t in m_s]\n",
    "\n",
    "fill_between(1:n_samples, zeros(n_samples), m_s_1, color=\"red\")\n",
    "fill_between(1:n_samples, m_s_1, m_s_1 + m_s_2, color=\"green\")\n",
    "fill_between(1:n_samples, m_s_1 + m_s_2, ones(n_samples), color=\"blue\")\n",
    "xlabel(\"Time\")\n",
    "ylabel(\"State belief\")\n",
    "grid(\"on\")\n",
    "title(\"Inferred state trajectory\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True state transition probabilities\n",
    "PyPlot.plt.matshow(A_data, cmap=\"bone\", vmin=0.0, vmax=1.0)\n",
    "ttl = title(\"True state transition probabilities\")\n",
    "ttl.set_position([.5, 1.15])\n",
    "yticks([0, 1, 2], [\"Red\", \"Green\", \"Blue\"])\n",
    "xticks([0, 1, 2], [\"Red\", \"Green\", \"Blue\"], rotation=\"vertical\")\n",
    "colorbar()\n",
    "\n",
    "# Inferred state transition probabilities\n",
    "PyPlot.plt.matshow(mean(marginals[:A]), cmap=\"bone\", vmin=0.0, vmax=1.0)\n",
    "ttl = title(\"Inferred state transition probabilities\")\n",
    "ttl.set_position([.5, 1.15])\n",
    "yticks([0, 1, 2], [\"Red\", \"Green\", \"Blue\"])\n",
    "xticks([0, 1, 2], [\"Red\", \"Green\", \"Blue\"], rotation=\"vertical\")\n",
    "colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
