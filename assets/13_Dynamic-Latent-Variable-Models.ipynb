{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic Latent Variable Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Introduction to dynamic (=temporal) Latent Variable Models, including the Hidden Markov Model and Kalman filter.   \n",
    "- Materials\n",
    "  - Mandatory\n",
    "    - These lecture notes\n",
    "  - Optional \n",
    "    - Bishop pp.605-615 on Hidden Markov Models\n",
    "    - Bishop pp.635-641 on Kalman filters\n",
    "    - Faragher (2012), [Understanding the Basis of the Kalman Filter](./files/Faragher-2012-Understanding-the-Basis-of-the-Kalman-Filter.pdf)\n",
    "    - Minka (1999), [From Hidden Markov Models to Linear Dynamical Systems](./files/Minka-1999-from-HMM-to-LDS.pdf)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Problem\n",
    "\n",
    "- <span class=\"exercise\">We consider a one-dimensional cart position tracking problem, see</span>  [Faragher 2012](./files/Faragher-2012-Understanding-the-Basis-of-the-Kalman-Filter.pdf).  \n",
    "\n",
    "- <span class=\"exercise\">The hidden states are the position $z_t$ and velocity $\\dot z_t$. We can apply an external acceleration/breaking force $u_t$. (Noisy) observations are represented by $x_t$.</span> \n",
    "\n",
    "- <span class=\"exercise\">The equations of motions are given by</span>\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\begin{bmatrix} z_t \\\\ \\dot{z_t}\\end{bmatrix} &=  \\begin{bmatrix} 1 & \\Delta t \\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix} z_{t-1} \\\\ \\dot z_{t-1}\\end{bmatrix} + \\begin{bmatrix} (\\Delta t)^2/2 \\\\ \\Delta t\\end{bmatrix} u_t + \\mathcal{N}(0,\\Sigma_z) \\\\\n",
    "x_t &= \\begin{bmatrix} z_t \\\\ \\dot{z_t}\\end{bmatrix} + \\mathcal{N}(0,\\Sigma_x) \n",
    "\\end{align*}$$\n",
    "\n",
    "- <span class=\"exercise\">Infer the position after 10 time steps.</span> \n",
    "\n",
    "<img src=\"./figures/Faragher-2012-cart-1.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dynamical Models\n",
    "\n",
    "<!--- - In this lesson, we consider models where the sequence order of observations matters. \n",
    "--->\n",
    "\n",
    "- Consider the _ordered_ observation sequence $x^T \\triangleq \\left(x_1,x_2,\\ldots,x_T\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We wish to develop a generative model\n",
    "    $$ p( x^T \\,|\\, \\theta)$$\n",
    "that 'explains' the time series $x^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We cannot use the IID assumption $p( x^T  | \\theta) = \\prod_t p(x_t \\,|\\, \\theta)$. In general, we _can_ use the [**chain rule**](https://en.wikipedia.org/wiki/Chain_rule_(probability) (a.k.a. the general product rule)\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(x^T) &= p(x_T|x^{T-1}) \\,p(x^{T-1}) \\\\\n",
    "  &=  p(x_T|x^{T-1}) \\,p(x_{T-1}|x^{T-2}) \\cdots p(x_2|x_1)\\,p(x_1) \\\\\n",
    "  &= p(x_1)\\prod_{t=2}^T p(x_t\\,|\\,x^{t-1})\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generally, we will want to limit the depth of dependencies on previous observations. For example, the $M$th-order linear **Auto-Regressive** (AR) model\n",
    "    $$\\begin{align*}\n",
    "  p(x_t|x^{t-1}) = \\mathcal{N}\\left( \\sum_{m=1}^M a_m x_{t-m}\\,,\\sigma^2\\,\\right)  \n",
    "    \\end{align*}$$\n",
    "    limits the dependencies to the past $M$ samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### State-space Models\n",
    "\n",
    "- A limitation of AR models is that they need a lot of parameters in order to create a flexible model. E.g., if $x_t$ is an $K$-dimensional discrete variable, then an $M$th-order AR model will have $K^{M-1}(K-1)$ parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Similar to our work on Gaussian Mixture models and latent Factor models, we can create a flexible dynamic system by introducing _latent_ (unobserved) variables  $z^T \\triangleq \\left(z_1,z_2,\\dots,z_T\\right)$ (one $z_t$ for each observation $x_t$). In dynamic systems, the latent variables $z_t$ are usually called _state variables_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A general **state space model** is defined by\n",
    "\n",
    "$$\\begin{align*}\n",
    "p&(z_t\\,|\\,z^{t-1}) \\tag{state transition model}  \\\\\n",
    "p&(x_t\\,|\\,z_t) \\tag{observation model}  \\\\\n",
    "p&(z_1) \\tag{initial state}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A very common computational assumption is to let state transitions be ruled by a _first-order Markov chain_ as\n",
    "$$\n",
    " p(z_t\\,|\\,z^{t-1}) = p(z_t\\,|\\,z_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The Markov assumption leads to the following joint probability distribution for the state-space model:\n",
    "$$\n",
    " p(x^T,z^T) = \\underbrace{p(z_1)}_{\\text{initial state}} \\prod_{t=2}^T \\underbrace{p(z_t\\,|\\,z_{t-1})}_{\\text{state transitions}}\\,\\prod_{t=1}^T \\underbrace{p(x_t\\,|\\,z_t)}_{\\text{observations}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The Forney-style factor graph for a state-space model:\n",
    "\n",
    "<img src=\"./figures/ffg-state-space.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- <span class=\"exercise\">Exercise: Show that in a state-space model $x_t$ is not a first-order Markov chain in the observations, i.e., show that $$p(x_t\\,|\\,x_{t-1},x_{t-2}) \\neq p(x_t\\,|\\,x_{t-1})\\,.$$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hidden Markov Models and Linear Dynamical Systems\n",
    "\n",
    "- A **Hidden Markov Model** (HMM) is a state-space model with <span class=\"emphasis\">discrete-valued</span> state variables $Z_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- E.g., $Z_t$ is a $K$-dimensional hidden binary 'class indicator' with transition probabilities $A_{jk} \\triangleq p(z_{tk}=1\\,|\\,z_{t-1,j}=1)$, or equivalently\n",
    "  $$p(z_t|z_{t-1}) = \\prod_{k=1}^K \\prod_{j=1}^K A_{jk}^{z_{t-1,j}z_{tk}}$$\n",
    "which is usually accompanied by an initial state distribution $\\pi_k \\triangleq p(z_{1k}=1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  \n",
    "- The classical HMM has also discrete-valued observations but in pratice any (probabilistic) observation model $p(x_t|z_t)$ may be coupled to the hidden Markov chain. \n",
    "\n",
    "<!---\n",
    "- The following figure shows the typical trellis structure of the many possible state transitions paths.   \n",
    "<img src=\"./figures/Figure13.7.png\" width=\"400px\">\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another well-known state-space model with <span class=\"emphasis\">continuous-valued</span> state variables $Z_t$ is the **(Linear) Gaussian Dynamical System** (LGDS), which is defined as\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(z_t\\,|\\,z_{t-1}) &= \\mathcal{N}\\left(\\, A z_{t-1}\\,,\\,\\Sigma_z\\,\\right) \\\\ \n",
    "p(x_t\\,|\\,z_t) &= \\mathcal{N}\\left(\\, C z_t\\,,\\,\\Sigma_x\\,\\right) \\\\\n",
    "p(z_1) &= \\mathcal{N}\\left(\\, \\mu_1\\,,\\,\\Sigma_1\\,\\right)\n",
    "\\end{align*}$$\n",
    "<!---or, equivalently (in the usual state-space notation)\n",
    "$$\\begin{align*}\n",
    "z_k &= A z_{k-1} + \\mathcal{N}\\left(0,\\Sigma_z \\right) \\\\ \n",
    "x_k &= C z_k + \\mathcal{N}\\left( 0, \\Sigma_x \\right) \\\\\n",
    "z_1 &= \\mu_1 + \\mathcal{N}\\left( 0, \\Sigma_1\\right)\n",
    "\\end{align*}$$\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Note that the joint distribution over $\\{(x_1,z_1),\\ldots,(x_t,z_t)\\}$ is a (large-dimensional) Gaussian distribution. This means that, in principle, every inference problem on the LGDS model also leads to a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- HMM's and LGDS's (and variants thereof) are at the basis of a wide range of complex information processing systems, such as speech and language recognition, robotics and automatic car navigation, and even processing of DNA sequences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kalman Filtering\n",
    "\n",
    "- Technically, a [**Kalman filter**](https://en.wikipedia.org/wiki/Kalman_filter) is the solution to the recursive estimation (inference) of the hidden state $z_t$ based on past observations in an LGDS, i.e., Kalman filtering solves the problem $p(z_t\\,|\\,x^t)$ based on the previous estimate $p(z_{t-1}\\,|\\,x^{t-1})$ and a new observation $x_t$ (in the context of the given model specification of course). \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    "- Let's infer the Kalman filter for a scalar linear Gaussian dynamical system:\n",
    "$$\\begin{align*}\n",
    "    p(z_t\\,|\\,z_{t-1}) &= \\mathcal{N}(z_t\\,|\\,a z_{t-1},\\sigma_z^2) \\tag{state transition}   \\\\\n",
    "    p(x_t\\,|\\,z_t) &= \\mathcal{N}(x_t\\,|\\,c z_t,\\sigma_x^2) \\tag{observation}     \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "        \n",
    "- Kalman filtering comprises inferring $p(z_t\\,|\\,x^t)$ from a given prior estimate $p(z_{t-1}\\,|\\,x^{t-1})$ and a new observation $x_t$. Let us assume that \n",
    "$$\\begin{align} \n",
    "p(z_{t-1}\\,|\\,x^{t-1}) = \\mathcal{N}(z_{t-1} \\,|\\, \\mu_{t-1}, \\sigma_{t-1}^2) \\tag{prior}\n",
    "\\end{align}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Note that everything is Gaussian, so this is _in principle_ possible to execute inference problems analytically and the result will be a Gaussian posterior:\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(z_t\\,|\\,x^t) &= p(z_t\\,|\\,x_t,x^{t-1}) \\propto p(x_t,z_t\\,|\\,x^{t-1}) \\\\\n",
    "  &\\propto p(x_t\\,|\\,z_t) \\,p(z_t\\,|\\,x^{t-1}) \\\\\n",
    "  &= p(x_t\\,|\\,z_t) \\, \\sum_{z_{t-1}} p(z_t,z_{t-1}\\,|\\,x^{t-1}) \\\\\n",
    "  &= \\underbrace{p(x_t\\,|\\,z_t)}_{\\text{observation}} \\, \\sum_{z_{t-1}} \\underbrace{p(z_t\\,|\\,z_{t-1})}_{\\text{state transition}} \\, \\underbrace{p(z_{t-1}\\,|\\,x^{t-1})}_{\\text{prior}} \\\\\n",
    "  &= \\mathcal{N}(x_t\\,|\\,c z_t,\\sigma_x^2) \\sum_{z_{t-1}} \\mathcal{N}(z_t\\,|\\,a z_{t-1},\\sigma_z^2) \\, \\mathcal{N}(z_{t-1} \\,|\\, \\mu_{t-1}, \\sigma_{t-1}^2) \\\\\n",
    "  &\\propto \\mathcal{N}\\left(z_t\\,\\bigm| \\,\\frac{x_t}{c} ,\\left(\\frac{\\sigma_x}{c}\\right)^2\\right) \\times \\mathcal{N}\\left(z_t\\, \\bigm|\\,a \\mu_{t-1},\\sigma_z^2 + \\left(a \\sigma_{t-1}\\right)^2 \\right) \\\\\n",
    "  &= \\mathcal{N}\\left( z_t \\,|\\, \\mu_t, \\sigma_t^2\\right)\n",
    "\\end{align*}$$\n",
    "with\n",
    "$$\\begin{align*}\n",
    "  \\rho_t^2 &= \\sigma_z^2 + a^2 \\sigma_{t-1}^2 \\tag{auxiliary variable}\\\\\n",
    "  K_t &= \\frac{c \\rho_t^2}{c^2 \\rho_t^2 + \\sigma_x^2} \\tag{'Kalman gain'} \\\\\n",
    "  \\mu_t &= a \\mu_{t-1} + K_t \\cdot \\left( x_t - c a \\mu_{t-1}\\right) \\tag{posterior mean}\\\\\n",
    "  \\sigma_t^2 &= \\left( 1 - K_t \\right) \\rho_t^2 \\tag{posterior variance}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Kalman filtering consists of computing these four equations for each new observation ($x_t$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In short, it is possible to analytically derive the Kalman filter for a linear dynamical system with Gaussian state and observation noise (eventhough it is not a fun exercise). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If anything changes in the model, e.g., the state noise is not Gaussian, then you have to re-derive the inference equations again from scratch and it may not lead to an analytically pleasing answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\Rightarrow$ Generally, we will want to automate the inference process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Message Passing in State-space Models\n",
    "\n",
    "- Once the (state-space) models have been specified, we can define state and parameter estimation problems as inference tasks on the generative model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In principle, for linear Gaussian models these inference tasks can be analytically solved, see e.g. [Faragher, 2012](./files/Faragher-2012-Understanding-the-Basis-of-the-Kalman-Filter.pdf) \n",
    "  - These derivations quickly become quite laborious  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Alternatively, we could specify the generative model in a (Forney-style) factor graph and use automated message passing to infer the posterior over the hidden variables. E.g., the message passing schedule for Kalman filtering looks like this: \n",
    "\n",
    "<img src=\"./figures/ffg-state-space-with-state-estimation.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Problem Revisited\n",
    "\n",
    "We can solve the cart tracking problem by sum-product message passing in a factor graph like the one depicted above. All we have to do is create factor nodes for the state-transition model $p(z_t|z_{t-1})$ and the observation model $p(x_t|z_t)$. Then we just build the factor graph and let ForneyLab (factor graph toolbox) perform message passing. \n",
    "\n",
    "We'll implement the following model:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\begin{bmatrix} z_t \\\\ \\dot{z_t}\\end{bmatrix} &=  \\begin{bmatrix} 1 & \\Delta t \\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix} z_{t-1} \\\\ \\dot z_{t-1}\\end{bmatrix} + \\begin{bmatrix} (\\Delta t)^2/2 \\\\ \\Delta t\\end{bmatrix} u_t + \\mathcal{N}(0,\\Sigma_z) \\\\\n",
    "\\mathbf{x}_t &= \\begin{bmatrix} z_t \\\\ \\dot{z_t}\\end{bmatrix} + \\mathcal{N}(0,\\Sigma_x)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: LoadError: UndefVarError: Node not defined\nwhile loading /Users/bert/github/bertdv/AIP-5SSB0/lessons/notebooks/scripts/linear_transition_model.jl, in expression starting on line 26\nwhile loading /Users/bert/github/bertdv/AIP-5SSB0/lessons/notebooks/scripts/cart_tracking_helpers.jl, in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: LoadError: UndefVarError: Node not defined\nwhile loading /Users/bert/github/bertdv/AIP-5SSB0/lessons/notebooks/scripts/linear_transition_model.jl, in expression starting on line 26\nwhile loading /Users/bert/github/bertdv/AIP-5SSB0/lessons/notebooks/scripts/cart_tracking_helpers.jl, in expression starting on line 1",
      "",
      " in include_from_node1(::String) at ./loading.jl:488",
      " in include_from_node1(::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?",
      " in include_from_node1(::String) at ./loading.jl:488",
      " in include_from_node1(::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?",
      " in include_string(::String, ::String) at ./loading.jl:441",
      " in include_string(::String, ::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?"
     ]
    }
   ],
   "source": [
    "include(\"scripts/cart_tracking_helpers.jl\") # implements required factor nodes + helper functions\n",
    "\n",
    "# Specify the model parameters\n",
    "Δt = 1.0                     # assume the time steps to be equal in size\n",
    "A = [1.0 Δt;\n",
    "     0.0 1.0]\n",
    "b = [0.5*Δt^2; Δt] \n",
    "Σz = diagm([0.2*Δt; 0.1*Δt]) # process noise covariance\n",
    "Σx = diagm([1.0; 2.0])       # observation noise covariance;\n",
    "\n",
    "# Generate noisy observations\n",
    "n = 10                # perform 10 timesteps\n",
    "z_start = [10.0; 2.0] # initial state\n",
    "u = 0.2 * ones(n)     # constant input u\n",
    "noisy_x = generateNoisyMeasurements(z_start, u, A, b, Σz, Σx);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since the factor graph is just a concatination of $n$ identical \"sections\", we only have to specify a single section, and ForneyLab will automatically build a 'virtual' factor graph consisting of $n$ sections. Let's build a section of the factor graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: TerminalNode not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: TerminalNode not defined",
      "",
      " in include_string(::String, ::String) at ./loading.jl:441",
      " in include_string(::String, ::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?"
     ]
    }
   ],
   "source": [
    "fg = FactorGraph()\n",
    "n_z_old      = TerminalNode(vague(MvGaussian{2}), id=:z_old)       # terminal for z[t-1]\n",
    "n_z_new      = TerminalNode(vague(MvGaussian{2}), id=:z_new)       # terminal for z[t]\n",
    "n_u          = TerminalNode(vague(Gaussian), id=:u)                # terminal for u[t]\n",
    "n_x          = TerminalNode(MvDelta(zeros(2)), id=:x)              # terminal for u[t]\n",
    "n_transition = LinearTransitionModelNode(A=A, b=b, Σ=Σz, id=:transition_model) # node p(z_new|z_old,u;A,b,Σ)\n",
    "n_equality   = EqualityNode()\n",
    "n_obs        = GaussianNode(V=Σx, id=:observation_model)                       # node p(x|z)\n",
    "\n",
    "Edge(n_z_old, n_transition.i[:z_old])\n",
    "Edge(n_u, n_transition.i[:u])\n",
    "Edge(n_transition.i[:z_new], n_equality.i[1])\n",
    "Edge(n_equality.i[2], n_obs.i[:mean])\n",
    "Edge(n_obs.i[:out], n_x)\n",
    "Edge(n_equality.i[3], n_z_new)\n",
    "\n",
    "Wrap(n_z_new, n_z_old) # Tell ForneyLab how to concatinate the sections\n",
    "# draw(fg);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we've built the factor graph, we can perform Kalman filtering by inserting measurement data into the factor graph and performing message passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: attachReadBuffer not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: attachReadBuffer not defined",
      "",
      " in include_string(::String, ::String) at ./loading.jl:441",
      " in include_string(::String, ::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?"
     ]
    }
   ],
   "source": [
    "# Insert data into graph, perform message-passing\n",
    "attachReadBuffer(n_u, map(Gaussian, u))      # insert values of u into terminal node n_u\n",
    "attachReadBuffer(n_x, map(MvDelta, noisy_x)) # insert the noisy measurements into terminal node n_x\n",
    "run(SumProduct()) # Perform sum-product message passing\n",
    "\n",
    "# Collect prediction p(z[n]|z[n-1]), measurement p(z[n]|x[n]), corrected prediction p(z[n]|z[n-1],x[n])\n",
    "prediction      = n_transition.i[:z_new].message.payload\n",
    "measurement     = n_obs.i[:mean].message.payload\n",
    "corr_prediction = n_equality.i[3].message.payload\n",
    "\n",
    "# Make a fancy plot of the prediction, noisy measurement, and corrected prediction after n timesteps\n",
    "plotCartPrediction(prediction, measurement, corr_prediction);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extensions\n",
    "\n",
    "<img src=\"./figures/fig-generative-Gaussian-models.png\" width=\"550px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-----\n",
    "_The cell below loads the style file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\n",
       "This HTML file contains custom styles and some javascript.\n",
       "Include it a Jupyter notebook for improved rendering.\n",
       "-->\n",
       "\n",
       "<!-- Fonts -->\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<!-- Custom style -->\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: rgb(245,245,245);\n",
       "}\n",
       "\n",
       "div.container {\n",
       "    min-width: 960px;\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    margin: auto;\n",
       "    padding-left: 0em;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "    margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running {\n",
       "    border: 1px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\n",
       "div.cell.code_cell {\n",
       "    background-color: rgb(256,256,256);\n",
       "    border-radius: 0px;\n",
       "    padding: 0.5em;\n",
       "    margin-left:1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Alegreya Sans' sans-serif;\n",
       "    line-height: 140%;\n",
       "    font-size: 125%;\n",
       "    font-weight: 400;\n",
       "    width:800px;\n",
       "    margin-left:auto;\n",
       "    margin-right:auto;\n",
       "}\n",
       "\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-style:regular;\n",
       "    font-weight: 400;\n",
       "    font-size: 45pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.3em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    margin-top:16px;\n",
       "    font-size: 22pt;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: regular;\n",
       "    color: rgb(102,102,0);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {    /*Use this for captions*/\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-size: 14pt;\n",
       "    text-align: center;\n",
       "    margin-top: 0em;\n",
       "    margin-bottom: 2em;\n",
       "    font-style: regular;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\n",
       "    font-family: 'Nixie One', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 16pt;\n",
       "    color: rgb(163,0,0);\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.8em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 { /*use this for copyright note*/\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 9pt;\n",
       "    line-height: 100%;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 90%;\n",
       "}\n",
       "\n",
       ".boxed { /* draw a border around a piece of text */\n",
       "  border: 1px solid blue ;\n",
       "}\n",
       "\n",
       "h4#CODE-EXAMPLE,\n",
       "h4#END-OF-CODE-EXAMPLE {\n",
       "    margin: 10px 0;\n",
       "    padding: 10px;\n",
       "    background-color: #d0f9ca !important;\n",
       "    border-top: #849f81 1px solid;\n",
       "    border-bottom: #849f81 1px solid;\n",
       "}\n",
       "\n",
       ".emphasis {\n",
       "    color: red;\n",
       "}\n",
       "\n",
       ".exercise {\n",
       "    color: green;\n",
       "}\n",
       "\n",
       ".proof {\n",
       "    color: blue;\n",
       "}\n",
       "\n",
       "code {\n",
       "  padding: 2px 4px !important;\n",
       "  font-size: 90% !important;\n",
       "  color: #222 !important;\n",
       "  background-color: #efefef !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\n",
       "   as they will be removed through some other method */\n",
       "@media not print {\n",
       "  .cell:nth-last-child(-n+2) {\n",
       "    display: none;\n",
       "  }\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<!-- MathJax styling -->\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"],\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f\n",
    "    display(\"text/html\", readstring(f))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
