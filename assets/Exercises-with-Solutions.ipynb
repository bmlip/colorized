{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>THIS NOTEBOOK IS UNDER CONSTRUCTION</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EXERCISES\n",
    "\n",
    "### Bayesian Machine Learning and Information Processing (5SSD0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In this notebook, we provide a set of exercises that should help you prepare for the exam. \n",
    "\n",
    "- For some of these exercises you will be able to find solutions quickly on the internet. Try to resist this route to solving the problems. You will not be graded for these exercises and solutions will be made available in a separate notebook. **Your ability to solve these exercises without external help (apart from Sam Roweis' cheat sheets) provides an excellent indicator of your readiness to pass the exam**. \n",
    "\n",
    "- Feel free to make use of Sam Roweis' cheat sheets for [Matrix identities](https://github.com/bertdv/BMLIP/blob/master/lessons/notebooks/files/Roweis-1999-matrix-identities.pdf) and [Gaussian identities](https://github.com/bertdv/BMLIP/blob/master/lessons/notebooks/files/Roweis-1999-gaussian-identities.pdf).\n",
    "  - These cheat sheets are not allowed at the exam but if needed we will provide the necessary formulas at the exam sheet.\n",
    "\n",
    "- The exercises are categorized by lesson headers, e.g., \"Probability Theory\" or \"Generative Classification\". Of course, for some exercises you may need some contents of some other (usually earlier) lessons or background materials. A perfect categorization is not feasible, but I've tried to link each question to a lesson so as to make it easier to test yourself after studying a specific lesson.     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Selected exercises from previous exams \"5SSB0\"\n",
    "\n",
    "##### Prelude \n",
    "- <span style=\"color:red\"> 5SSB0 (Adaptive Information Processing) was last taught at TU/e in the academic year 2018/19. Starting with the academic year 2019/20, the current class (5SSD0) is offered instead. In comparison to 5SSB0, the emphasis of the current class is more on the Bayesian framework (rather than maximum likelihood). Below, we present a selection of exercises that were used in the 5SSB0 exams. While these exercises may not represent the emphasis on Bayesian methods, they do represent the \"style of questions\" and the \"level of difficulty\" that you may expect in upcoming 5SSD0 exams. Also, there is nothing in the questions below that is considered outside the scope of 5SSD0. </span>\n",
    "\n",
    "- The following formulas (matrix calculus and MVG) were provided for your convenience at the exam sheet:\n",
    "\n",
    "  - Some Matrix Calculus \n",
    "$$\\begin{align*}\n",
    "|A^{-1}|&=|A|^{-1} \\\\\n",
    "\\nabla_A \\log |A| &= (A^{T})^{-1} = (A^{-1})^T \\\\\n",
    "\\mathrm{Tr}[ABC]&= \\mathrm{Tr}[CAB] = \\mathrm{Tr}[BCA]  \\\\\n",
    "\\nabla_A \\mathrm{Tr}[AB] &=\\nabla_A \\mathrm{Tr}[BA]= B^T  \\\\\n",
    "\\nabla_A \\mathrm{Tr}[ABA^T] &= A(B+B^T)\\\\\n",
    " \\nabla_x x^TAx &= (A+A^T)x\\\\\n",
    "\\nabla_X a^TXb &= \\nabla_X \\mathrm{Tr}[ba^TX] = ab^T\n",
    "\\end{align*}$$\n",
    "\n",
    "  - Definition of the Multivariate Gaussian Distribution (MVG)\n",
    "$$\n",
    "\\mathcal{N}(x|\\,\\mu,\\Sigma) = |2 \\pi \\Sigma|^{-\\frac{1}{2}} \\exp\\left\\{-\\frac{1}{2}(x-\\mu)^T\n",
    "\\Sigma^{-1} (x-\\mu) \\right\\}\n",
    "$$\n",
    "\n",
    "##### The questions\n",
    "\n",
    "- For each of the following sub-questions, you are asked to provide\n",
    "a *short but essential* answer. You should not need more than\n",
    "three sentences per answer.\n",
    "\n",
    "1. Consider a binary classification problem with two classes $\\{y_1,y_2\\}$ and input vector $x$. We are given a data set to train the parameters $\\theta$ for a likelihood model of the form\n",
    "$$\n",
    "p(y_k=1|x,\\theta) = \\frac{1}{1 + e^{-\\theta_k^T x}}\n",
    "$$\n",
    "There a two fundamentally different ways to train $\\theta$, namely through a generative model or by discriminative training.     \n",
    "  (a) Explain shortly how we train $\\theta$ through a generative model. No need to work out all equations for Gaussian models, but explain the strategy in probabilistic modeling terms.     \n",
    "  (b) Explain shortly how we train $\\theta$ through a discriminative\n",
    "approach.  \n",
    "> (a) In a generative model, the class posterior is obtained through\n",
    "Bayes rule,\n",
    "$$\n",
    "p(y_k=1|x,\\theta) \\propto p(x|y_k=1,\\theta) p(y_k=1|\\theta)\n",
    "$$\n",
    "In terms of ML training, this means we maximize the *joint* log-likelihood $\\sum_n \\log p(x_n,y_n|\\theta)$ wrt $\\theta$. This leads to a structured breakdown of the model (and parameters) into a class-conditional likelihood $ p(x|y_k=1,\\theta) $ and class priors $p(y_k=1|\\theta)$.     \n",
    "> (b) In a discriminative model, the posterior class density\n",
    "$ p(y_k=1|x,\\theta) $  is directly trained, i.o.w. we maximize the\n",
    "*conditional* log-likelihood $\\sum_n \\log p(y_{nk}|x_n\\theta)$.\n",
    "There's no structured model breakdown.\n",
    "\n",
    "- Explain shortly how Bayes rule relates to machine learning. In your answer, you may assume a model $\\mathcal{M}$ with prior distribution $p(\\mathcal{M})$ and an observed data set $D$.     \n",
    ">  $$ \\underbrace{p(\\mathcal{M}|D)}_{\\text{posterior}} = \\frac{p(D|\\mathcal{M})}{p(D)}\\underbrace{p(\\mathcal{M})}_{\\text{prior}}\n",
    "$$\n",
    "Bayes rule relates what we know about a model before (prior) and\n",
    "after (posterior) having seen the data. The difference between the\n",
    "prior and posterior distributions for the model can be interpreted\n",
    "as a \"machine learning\" effect. (Alternative answers are also\n",
    "possible).\n",
    "\n",
    "- What is the difference between supervised and unsupervised learning? Express the goals of these two learning methods in terms of a probability distribution. (I'm looking here for a statement such as: \" Given $\\ldots$, the goals of supervised/unsupervised learning is to estimate $p(\\cdot|\\cdot)$\".)      \n",
    "> Given data $D=\\{(x_1,y_1),\\ldots,(x_N,y_N)\\}$ and a model $p(y|x,\\theta)$, the goal of supervised learning is to estimate $p(\\theta|D)$. Given data $D=\\{x_1,\\ldots,x_N\\}$ and a model $p(x|\\theta)$, the goal of unsupervised learning is to estimate $p(\\theta|D)$. \n",
    "\n",
    "- In a particular model with hidden variables, the log-likelihood can be worked out to the following expression:\n",
    "$$\n",
    " L(\\theta) = \\sum_n \\log \\left(\\sum_k \\pi_k\\,\\mathcal{N}(x_n|\\mu_k,\\Sigma_k)\\right)\n",
    "$$\n",
    "Do you prefer a gradient descent or EM algorithm to estimate maximum likelihood values for the parameters?  Explain your answer. (No need to work out the equations.)\n",
    "> Since this expression does not degenerate into simple MVGs, the EM approach is in practice preferred.\n",
    "\n",
    "- Consider a data set $D = \\{x_1,x_2,\\ldots,x_N\\}$ where we assume that each sample $x_n$ is IID distributed by a multivariate Gaussian (MVG), $\\mathcal{N}(x_n|\\,\\mu,\\Sigma)$. \n",
    "Proof that the maximum likelihood estimate (MLE) of the mean value of this distribution is given by\n",
    "$$\\begin{equation*}\n",
    "\\hat \\mu = \\frac{1}{N}\\sum_n x_n \n",
    "\\end{equation*}$$      \n",
    "> $$\\begin{align*}\n",
    "\\nabla_\\mu \\log p(D|\\theta) &= -\\frac{1}{2}\\sum_n \\nabla_\\mu \\left( (x_n-\\mu)^T \\Sigma^{-1} (x_n-\\mu) \\right)  \\\\\n",
    "&= -\\frac{1}{2}\\sum_n \\nabla_\\mu \\mathrm{Tr} \\left[ -2\\mu^T\\Sigma^{-1}x_n + \\mu^T\\Sigma^{-1}\\mu \\right] \\\\\n",
    "&= -\\frac{1}{2}\\sum_n \\left( -2\\Sigma^{-1} x_n + 2\\Sigma^{-1}\\mu \\right)  \\\\\n",
    "&= \\Sigma^{-1}\\,\\sum_n \\left( x_n-\\mu \\right)\n",
    "\\end{align*}$$\n",
    "Set to zero yields\n",
    "$$\n",
    "\\hat \\mu = \\frac{1}{N} \\sum_n x_n\n",
    "$$\n",
    "\n",
    "\n",
    "\\begin{deelvraag}\n",
    "Consider now a data set $\\data = \\xyset$ with 1-of-$K$ notation for the discrete classes, i.e.,\n",
    "$$\n",
    "\\y_{nk} = \\begin{cases} 1 & \\text{if $\\y_n$ in class $\\class_k$}\\\\\n",
    "        0 & \\text{else} \\end{cases}\n",
    "$$\n",
    "together with class-conditional distribution $p(\\xv|\\class_k,\\thvec) = \\N(\\xv|\\muvec_k,\\Sgm)$ and multinomial prior $p(\\class_k|\\priovec) = \\prio_k$.\n",
    "\n",
    "Proof that the joint log-likelihood is given by\n",
    "$$\n",
    "\\log \\p(\\data|\\thvec) =  \\sum_{n,k} \\y_{nk} \\log \\N(\\xv_n|\\muvec_k,\\Sgm) + \\sum_{n,k} \\y_{nk} \\log \\prio_k\n",
    "$$\n",
    "\\tjboxed{\n",
    " \\begin{align*}\n",
    " \\log p(\\data|\\thvec) &= \\sum_n \\log \\red{\\prod_k} p(\\xv_n,\\red{\\y_{nk}}|\\thvec)^\\red{{\\y_{nk}}} =  \\sum_{n,k} \\y_{nk} \\log  \\blue{p(\\xv_n,\\y_{nk}|\\thvec)}\\\\\n",
    "     &=  \\sum_{n,k} \\y_{nk} \\log \\blue{\\N(\\xv_n|\\muvec_k,\\Sgm)} + \\sum_{n,k} \\y_{nk} \\log \\blue{\\prio_k}\n",
    " \\end{align*}\n",
    "}%end tjboxed\n",
    "\\end{deelvraag}\n",
    "\n",
    "\\begin{deelvraag}\n",
    "Show now that the MLE of the \\emph{class-conditional} mean is given by\n",
    "\\begin{equation}\\label{eq:clas-mu}\n",
    " \\hat \\muvec_k = \\frac{\\sum_n \\y_{nk} \\xv_n}{\\sum_n \\y_{nk}} \n",
    "\\end{equation}\n",
    "\\tjboxed{  see lecture notes. } % end tjboxed\n",
    "\\end{deelvraag}\n",
    "\n",
    "\\begin{deelvraag}\n",
    "Explain this formula (eqn 2) in relation to eqn 1,  the MLE for the mean of a MVG.\n",
    "\\tjboxed{Eqn 2 computes the sample proportion, just like eqn 1 , but now only for samples from class $k$. \n",
    "} % end tjboxed\n",
    "\\end{deelvraag}\n",
    "\n",
    "\\begin{deelvraag}\n",
    "In the lecture notes, we also discussed the MLE for a \\emph{clustering} problem and derived (for the $i$-th iteration of the EM algorithm):\n",
    "\\begin{equation}\n",
    "\\hat \\muvec_k^{(i)} = \\frac{\\sum_n \\resp_{nk}^{(i)} \\xv_n}{\\sum_n \\resp_{nk}^{(i)}}\n",
    "\\label{eq:clus-mu}\n",
    "\\end{equation}\n",
    "(i) What does $\\resp_{nk}^{(i)}$ represent?\\\\\n",
    "(ii) Express $\\resp_{nk}^{(i)}$ in terms of $\\z_{nk}$  and $\\xv_n$\\\\\n",
    "(iii) Why the iterative EM algorithm? \n",
    "\\tjboxed{\n",
    "(1) The responsibilty $\\resp_{nk}^{(i)} = \\Exp[\\z_{nk}|\\xv_n,\\thvec^{(i-1)}]$ is a \\emph{soft} class indicator.\\\\ (2) It is our best estimate of the binary class indicator $\\y_{nk}$, given the input $\\xv_n$.\\\\ (3) We need the iterative EM algorithm because in clustering we don't have a one-step solution to the maximum likelihood estimation problem.\n",
    "} % end tjboxed\n",
    "\\end{deelvraag}\n",
    "\n",
    "\\end{vraag}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Machine Learning Overview\n",
    "\n",
    "1. Pick three applications from the [\"Some Machine Learning Applications\"](https://nbviewer.jupyter.org/github/bertdv/BMLIP/blob/master/lessons/notebooks/Machine-Learning-Overview.ipynb#some-ml-apps)-slide and (shortly) describe for each application how (a combination of) clustering, dimensionality reduction, regression classification or reinforcement learning could accomplish the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probability Theory Review\n",
    "\n",
    "\n",
    "1. Proof that $p(A|I) + p(\\bar{A}|I) = 1$ follows from the sum rule.\n",
    "\n",
    "- Box 1 contains 8 apples and 4 oranges. Box 2 contains 10 apples and 2 oranges. Boxes are chosen with equal probability.     \n",
    "  (a) What is the probability of choosing an apple?        \n",
    "  (b) If an apple is chosen, what is the probability that it came from box 1?\n",
    "> The following probabilities are given in the problem statement,\n",
    "$$\\begin{align*}\n",
    "p(b_1) &= p(b_2) = 1/2\\\\\n",
    "p(a|b_1) &= 8/12,  \\quad p(a|b_2)=10/12\\\\\n",
    "p(o|b_1) &= 4/12,  \\quad p(o|b_2)=2/12\n",
    "\\end{align*}$$\n",
    "> \n",
    "> (a) $p(a) = \\sum_i p(a,b_i) = \\sum_i p(a|b_i)p(b_i)=\\frac{8}{12}\\cdot\\frac{1}{2} + \\frac{10}{12}\\cdot\\frac{1}{2} = \\frac{3}{4}$       \n",
    "> (b) $p(b_1|a) = \\frac{p(a,b_1)}{p(a)} = \\frac{p(a|b_1)p(b_1)}{p(a)} = \\frac{\\frac{8}{12}\\cdot\\frac{1}{2}}{\\frac{3}{4}} = \\frac{4}{9}$\n",
    "\n",
    "-  Derive the *generalized sum rule*,\n",
    "    $$p(A + B) = p(A) + p(B) - p(A,B)$$\n",
    "from the \"elementary\" sum rule $p(A) + p(\\bar A) = 1$ and the product rule. Use the fact that $A + B = \\overline {\\bar A \\bar B }$ (from Boolean logic). \n",
    "> $$\\begin{align*}\n",
    "  p\\left( {A + B} \\right)  &\\underset{\\mathrm{bool}}{=}  p\\left( {\\overline {\\bar A \\bar B } } \\right) \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} 1 - p\\left( {\\bar A \\bar B } \\right) \\\\\n",
    "    &\\underset{\\mathrm{prod}}{=} 1 - p\\left( {\\bar A |\\bar B } \\right)p\\left( {\\bar B } \\right) \\\\\n",
    "    &\\underset{\\mathrm{prod}}{=} 1 - \\left( {1 - p\\left( {A|\\bar B } \\right)} \\right)\\left( {1 - p\\left( B \\right)} \\right) \\\\\n",
    "    &= p(B) + \\left( {1 - p\\left( B \\right)} \\right)p\\left( {A|\\bar B } \\right)  \\\\\n",
    "    &\\underset{\\mathrm{prod}}{=} p(B) + \\left( {1 - p\\left( B \\right)} \\right)p\\left( {\\bar B |A} \\right)\\frac{{p\\left( A \\right)}}\n",
    "{{p\\left( {\\bar B } \\right)}} \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} p(B) + p\\left( {\\bar B |A} \\right)p\\left( A \\right) \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} p(B) + \\left( {1 - p\\left( {B|A} \\right)} \\right)p\\left( A \\right)  \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} p\\left( A \\right) + p(B) - p\\left( {A,B} \\right) \n",
    "\\end{align*}$$\n",
    "If $A$ and $B$ can not be true at the same time (we say: $A$ and $B$ are *mutually exclusive*), it follows that $p(A,B)=0$ and consequently in this case $p(A+B) = p(A) + p(B)$. \n",
    "\n",
    "- The inhabitants of an island tell the truth one third of the time. They lie with probability $2/3$. On an occasion, after one of them made a statement, you ask another \"was that statement true?\" and he says \"yes\". What is the probability that the statement was indeed true?\n",
    "> We use variables $S_1$ and $S_2$ for statements 1 and 2 and shorthand \"y\", \"n\", \"t\" and \"f\" for \"yes\", \"no\", \"true and \"false\", respectively. The problem statement provides us with the following probabilities,\n",
    "$$\\begin{align*}\n",
    "p(S_1=\\text{t})&= 1/3\\\\\n",
    "p(S_1=\\text{f})&= 1 - p(S_1=\\text{t})= 2/3\\\\\n",
    "p(S_2=\\text{y}|S_1=\\text{t})&= 1/3 \\\\\n",
    "p(S_2=\\text{y}|S_1=\\text{f})&= 1-p(S_2=\\text{y}|S_1=\\text{t})= 2/3\n",
    "\\end{align*}$$\n",
    "We are asked to compute $p(S_1=\\text{t}|S_2=\\text{y})$. Use Bayes rule,\n",
    "$$\\begin{align*}\n",
    "p(S_1=\\text{t}|S_2=\\text{y}) &= \\frac{p(S_1=\\text{t},S_2=\\text{y})}{p(S_2=\\text{y})}\\\\\n",
    "&=\\frac{p(S_2=\\text{y}|S_1=\\text{t})p(S_1=\\text{t})}{p(S_2=\\text{y}|S_1=\\text{t})p(S_1=\\text{t})+p(S_2=\\text{y}|S_1=\\text{f})p(S_1=\\text{f})}\\\\\n",
    "&= \\frac{\\frac{1}{3}\\cdot\\frac{1}{3}}{\\frac{1}{3}\\cdot\\frac{1}{3}+\\frac{2}{3}\\cdot\\frac{2}{3}} = \\frac{1}{5}\n",
    "\\end{align*}$$\n",
    "\n",
    "- A bag contains one ball, known to be either white or black. A white ball is put in, the bag is shaken, and a ball is drawn out, which proves to be white. What is now the chance of drawing a white ball? (Note that the state of the bag, after the operations, is exactly identical to its state before.)\n",
    "> There are two hypotheses: let $H = 0$ mean that the original ball in the bag was white and $H = 1$ that is was black.\n",
    "Assume the prior probabilities are equal. The data is that when a randomly selected ball was drawn from the bag, which contained a white one and the unknown one, it turned out to be white. The probability of this result according to each hypothesis is:\n",
    "$$ P(D|H =0) = 1,\\quad P(D|H =1) = 1/2$$\n",
    "So by Bayes theorem, the posterior probability of $H$ is\n",
    "$$P(H =0|D) = 2/3,\\quad P(H =1|D) = 1/3$$\n",
    "\n",
    "- A dark bag contains five red balls and seven green ones.      \n",
    "  (a) What is the probability of drawing a red ball on the first draw?      \n",
    "  (b) Balls are not returned to the bag after each draw. If you know that on the second draw the ball was a green one, what is now the probability of drawing a red ball on the first draw?       \n",
    "> (a) $p(S_1=R) = \\frac{N_R}{N_R+N_G}= \\frac{5}{12}$        \n",
    "> (b) The outcome of the $n$th draw is referred to by variable $S_n$. Use Bayes rule to get \n",
    "$$\\begin{align*}\n",
    "p(S_1=\\text{R}|S_2=\\text{G}) &=\\frac{p(S_2=\\text{G}|S_1=\\text{R})p(S_1=\\text{R})}{p(S_2=\\text{G}|S_1=\\text{R})p(S_1=\\text{R})+p(S_2=\\text{G}|S_1=\\text{G})p(S_1=\\text{G})}\\\\\n",
    "&= \\frac{\\frac{7}{11}\\cdot\\frac{5}{12}}{\\frac{7}{11}\\cdot\\frac{5}{12}+\\frac{6}{11}\\cdot\\frac{7}{12}} = \\frac{5}{11}\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "- Is it more correct to speak about the likelihood of a _model_ (or model parameters) than about the likelihood of an _observed data set_. And why? \n",
    "\n",
    "- Is a speech signal a 'probabilistic' (random) or a deterministic signal?\n",
    "\n",
    "- A dark bag contains five red balls and seven green ones. (a) What is the probability of drawing a red ball on the first draw? Balls are not returned to the bag after each draw. (b) If you know that on the second draw the ball was a green one, what is now the probability of drawing a red ball on the first draw?\n",
    "\n",
    "- A bag contains one ball, known to be either white or black. A white ball is put in, the bag is shaken,\n",
    " and a ball is drawn out, which proves to be white. What is now the\n",
    " chance of drawing a white ball?\n",
    " \n",
    "- Proof that, the mean and (co-)variance of any distribution $p(x)$ is processed by a linear tranformation as\n",
    " $$\\begin{align}\n",
    "\\mathrm{E}[Ax +b] &= A\\mathrm{E}[x] + b \\tag{SRG-3a}\\\\\n",
    "\\mathrm{cov}[Ax +b] &= A\\,\\mathrm{cov}[x]\\,A^T \\tag{SRG-3b}\n",
    "\\end{align}$$\n",
    "\n",
    "- Proof that, for any distribution of $x$ and $y$ and $z=x+y$\n",
    "$$\\begin{align*}\n",
    "    \\mathrm{E}[z] &= \\mathrm{E}[x] + \\mathrm{E}[y] \\\\\n",
    "    \\mathrm{var}[z] &= \\mathrm{var}[x] + \\mathrm{var}[y] + 2\\mathrm{cov}[x,y] \n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "- $$\\begin{align*}\n",
    "    \\mathrm{E}[z] &= \\int_z z \\left[\\int_x p_x(x)p_y(z-x) \\,\\mathrm{d}{x} \\right] \\,\\mathrm{d}{z} \\\\\n",
    "&= \\int_x p_x(x) \\left[ \\int_z z p_y(z-x)\\,\\mathrm{d}{z} \\right] \\,\\mathrm{d}{x}  \\\\\n",
    "    &= \\int_x p_x(x) \\left[ \\int_{y^\\prime} (y^\\prime +x)p_y(y^\\prime)\\,\\mathrm{d}{y^\\prime} \\right] \\,\\mathrm{d}{x} \\notag\\\\\n",
    "&= \\int_x p_x(x) \\left( \\mathrm{E}[y]+x \\right) \\,\\mathrm{d}{x} \\notag\\\\\n",
    "    &= \\mathrm{E}[x] + \\mathrm{E}[y] \\qquad \\text{(always; follows from SRG-3a)}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Machine Learning\n",
    "\n",
    "1. (a) Explain shortly the relation between machine learning and Bayes rule.     \n",
    "  (b) How are Maximum a Posteriori (MAP) and Maximum Likelihood (ML) estimation related to Bayes rule and machine learning?\n",
    "> (a) Machine learning is inference over models (hypotheses, parameters, etc.) from a given data set. *Bayes rule* makes this statement precise. Let $\\theta \\in \\Theta$ and $D$ represent a model parameter vector and the given data set, respectively. Then, Bayes rule,\n",
    "$$\n",
    "p(\\theta|D) = \\frac{p(D|\\theta)}{p(D)} p(\\theta)\n",
    "$$\n",
    "relates the information that we have about $\\theta$ before we saw the data (i.e., the distribution $p(\\theta)$) to what we know after having seen the data, $p(\\theta|D)$.      \n",
    "> (b) The *Maximum a Posteriori* (MAP) estimate picks a value $\\hat\\theta$ for which the posterior distribution $p(\\theta|D)$ is maximal, i.e.,\n",
    "$$ \\hat\\theta_{MAP} = \\arg\\max_\\theta p(\\theta|D)$$\n",
    "In a sense, MAP estimation approximates Bayesian learning, since we approximated $p(\\theta|D)$ by $\\delta(\\theta-\\hat\\theta_{\\text{MAP}})$. Note that, by Bayes rule, $$\\arg\\max_\\theta p(\\theta|D) = \\arg\\max_\\theta p(D|\\theta)p(\\theta)$$\n",
    "If we further assume that prior to seeing the data all values for $\\theta$ are equally likely (i.e., $p(\\theta)=\\text{const.}$), then the MAP estimate reduces to the *Maximum Likelihood* estimate,\n",
    "$$ \\hat\\theta_{ML} = \\arg\\max_\\theta p(D|\\theta)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Proof that the Bayes estimate minimizes the expected mean-square error, i.e., proof that\n",
    "\n",
    "$$\n",
    "\\hat \\theta_{bayes} = \\arg\\min_{\\hat \\theta} \\int_\\theta (\\hat \\theta -\\theta)^2 p \\left( \\theta |D \\right) \\,\\mathrm{d}{\\theta}\n",
    "$$\n",
    "\n",
    "- on the Bayes factor ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Continuous Data and the Gaussian Distribution\n",
    "\n",
    "\n",
    "1. We are given an IID data set $D = \\{x_1,x_2,\\ldots,x_N\\}$, where $x_n \\in \\mathbb{R}^M$. Let's assume that the data were drawn from a multivariate Gaussian (MVG),\n",
    "$$\\begin{align*}\n",
    "p(x_n|\\theta) = \\mathcal{N}(x_n|\\,\\mu,\\Sigma) = |2 \\pi \\Sigma|^{-\\frac{1}{2}} \\exp\\left\\{-\\frac{1}{2}(x_n-\\mu)^T\n",
    "\\Sigma^{-1} (x_n-\\mu) \\right\\}\n",
    "\\end{align*}$$      \n",
    "  (a) Derive the log-likelihood of the parameters for these data.       \n",
    "  (b) Derive the maximum likelihood estimates for $\\mu$ and $\\Sigma$ by setting the derivative of the log-likelihood to zero.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Proof that a **linear transformation** $z=Ax+b$ of a Gaussian variable $\\mathcal{N}(x|\\mu,\\Sigma)$ is Gaussian distributed as\n",
    "$$\n",
    "p(z) = \\mathcal{N} \\left(z \\,|\\, A\\mu+b, A\\Sigma A^T \\right) \\tag{SRG-4a}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- Given independent variables\n",
    "$x \\sim \\mathcal{N}(\\mu_x,\\sigma_y^2)$ and $y \\sim \\mathcal{N}(\\mu_y,\\sigma_y^2)$, what is the PDF for $z = A\\cdot(x -y) + b$ ?\n",
    "<img src=\"./figures/fig-linear-system.png\" width=\"350px\">\n",
    "- (Answer): $z$ is also Gaussian with \n",
    "$$\n",
    "p_z(z) = \\mathcal{N}(z \\,|\\, A(\\mu_x-\\mu_y)+b, \\, A (\\sigma_x^2 + \\sigma_y^2) A^T)\n",
    "$$\n",
    "\n",
    "- Show that Eq.SRG-8 is a special case of Eq.SRG-4a. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Proof\n",
    "$$\n",
    "p(x,\\theta) = \\mathcal{N} \\left( \\begin{bmatrix} x\\\\ \n",
    "  \\theta  \\end{bmatrix} \n",
    "  \\,\\left|\\, \\begin{bmatrix} \\mu_0\\\\ \n",
    "  \\mu_0\\end{bmatrix}, \n",
    "         \\begin{bmatrix} \\sigma_0^2+\\sigma^2  & \\sigma_0^2\\\\ \n",
    "         \\sigma_0^2 &\\sigma_0^2 \n",
    "  \\end{bmatrix} \n",
    "  \\right. \\right)\n",
    "$$\n",
    "- Look up conditioning and marginalization in canonical coordinates and compare to the formulas for the moment parameterization of the Gaussian. Any conclusions?\n",
    "\n",
    "- Derive $$\\begin{align*}\n",
    "p(\\theta|x) &= \\mathcal{N} \\left( \\theta\\,|\\,\\mu_1, \\sigma_1^2 \\right)\\,,\n",
    "\\end{align*}$$\n",
    "with\n",
    "$$\\begin{align*}\n",
    "K &= \\frac{\\sigma_0^2}{\\sigma_0^2+\\sigma^2} \\qquad \\text{($K$ is called: Kalman gain)}\\\\\n",
    "\\mu_1 &= \\mu_0 + K \\cdot (x-\\mu_0)\\\\\n",
    "\\sigma_1^2 &= \\left( 1-K \\right) \\sigma_0^2  \n",
    "\\end{align*}$$\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete Data and the Multinomial Distribution\n",
    "\n",
    "1. Now we consider IID data $D = \\{x_1,x_2,\\ldots,x_N\\}$ obtained from tossing a $K$-sided die. We use a *binary selection variable*\n",
    "$$x_{nk} \\equiv \\begin{cases} 1 & \\text{if $x_n$ lands on $k$th face}\\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "with probabilities $p(x_{nk} = 1)=\\theta_k$.      \n",
    "  (a) Write down the probability for the $n$th observation $p(x_n|\\theta)$ and derive the log-likelihood $\\log p(D|\\theta)$.     \n",
    "  (b) Derive the maximum likelihood estimate for $\\theta$.\n",
    "> See lecture notes (on class homepage).      \n",
    "  (a) $p(x_n|\\theta) = \\prod_k \\theta_k^{x_{nk}} \\quad \\text{subject to} \\quad \\sum_k \\theta_k = 1$.\n",
    "$$\\ell(\\theta)  = \\sum_k m_k \\log \\theta_k$$\n",
    "where $m_k = \\sum_k x_{nk}$.     \n",
    "  (b) $\\hat \\theta = \\frac{m_k}{N}$, the \\emph{sample proportion}.\n",
    "\n",
    "- The probability that we throw the $k$th face at the next toss was \n",
    "$$\\begin{align*}\n",
    "p(x_{\\bullet,k}=1|D) = \\frac{m_k + \\alpha_k }{ N+ \\sum_k \\alpha_k}\n",
    "\\end{align*}$$\n",
    "Does this answer make sense?\n",
    "\n",
    "- Verify for yourself that ([Exercise](https://nbviewer.jupyter.org/github/bertdv/BMLIP/blob/master/lessons/notebooks/Exercises.ipynb)): \n",
    "  - the categorial distribution is a special case of the multinomial for $N=1$. \n",
    "  - the Bernoulli is a special case of the categorial distribution for $K=2$.\n",
    "  - the binomial is a special case of the multinomial for $K=2$.\n",
    "\n",
    "- Show that [Laplace's generalized rule of succession](#prediction-loaded-die) can be worked out to a prediction that is composed of a prior prediction and data-based correction term.  \n",
    "\n",
    "- We didn't use a co-variance matrix for discrete data. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression\n",
    "\n",
    "\n",
    "- Let's work out the log-likelihood for multiple observations\n",
    "$$\\begin{align*}\n",
    "\\log p(D|w) &\\stackrel{\\text{IID}}{=} \\sum_n \\log \\mathcal{N}(y_n|\\,w^T x_n,\\sigma^2) \\propto -\\frac{1}{2\\sigma^2} \\sum_{n} {(y_n - w^T x_n)^2}\\\\\n",
    "    &= -\\frac{1}{2\\sigma^2}\\left( {y - \\mathbf{X}w } \\right)^T \\left( {y - \\mathbf{X} w } \\right)\n",
    "\\end{align*}$$\n",
    "where  we defined $N\\times 1$ vector $y  = \\left(y_1 ,y_2 , \\ldots ,y_N \\right)^T$ and $(N\\times D)$-dim matrix $\\mathbf{X}  = \\left( x_1 ,x_2 , \\ldots ,x_n \\right)^T$.\n",
    "\n",
    "\n",
    "- - Now, we want to apply the trained model. New data points can be predicted by\n",
    "$$\\begin{equation*}\n",
    "p(y_\\bullet \\,|\\, x_\\bullet,\\hat w_{\\text{ML}}) = \\mathcal{N}(y_\\bullet \\,|\\, \\hat w_{\\text{ML}}^T x_\\bullet, \\sigma^2 ) \n",
    "\\end{equation*}$$\n",
    "\n",
    "- Note that the expected value of a predicted new data point\n",
    "\n",
    "$$\n",
    "\\mathrm{E}[y_\\bullet] = \\hat w_{\\text{ML}}^T x_\\bullet = x_\\bullet^T \\hat{w}_{\\text{ML}} = \\left( x_\\bullet^T \\mathbf{X}^\\dagger \\right) y\n",
    "$$\n",
    "\n",
    "can also be expressed as a linear combination of the observed data points \n",
    "\n",
    "$$y  = \\left( {y_1 ,y_1 , \\ldots ,y_N } \\right)^T \\,.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generative Classification\n",
    "\n",
    "1. You have a machine that measures property $x$, the \"orangeness\" of liquids. You wish to discriminate between $C_1 = \\text{`Fanta'}$ and $C_2 = \\text{`Orangina'}$. It is known that\n",
    "$$\\begin{align*}\n",
    "p(x|C_1) &= \\begin{cases} 10 & 1.0 \\leq x \\leq 1.1\\\\\n",
    "    0 & \\text{otherwise}\n",
    "    \\end{cases}\\\\\n",
    "p(x|C_2) &= \\begin{cases} 200(x - 1) & 1.0 \\leq x \\leq 1.1\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{align*}$$\n",
    "The prior probabilities $p(C_1) = 0.6$ and $p(C_2) = 0.4$ are also known from experience.       \n",
    "  (a) A \"Bayes Classifier\" is given by\n",
    "$$ \\text{Decision} = \\begin{cases} C_1 & \\text{if } p(C_1|x)>p(C_2|x) \\\\\n",
    "                               C_2 & \\text{otherwise}\n",
    "                 \\end{cases}$$\n",
    "Calculate the optimal Bayes classifier.      \n",
    "  (b) The probability of making the wrong decision, given $x$, is\n",
    "$$\\begin{equation*}\n",
    "p(\\text{error}|x)= \\begin{cases} p(C_1|x) & \\text{if we decide $C_2$}\\\\\n",
    "    p(C_2|x) & \\text{if we decide $C_1$}\n",
    "\\end{cases}\n",
    "\\end{equation*}$$\n",
    "Compute the **total** error probability  $p(\\text{error})$ for the Bayes classifier in this example.\n",
    "> (a) We choose $C_1$ if $p(C_1|x)/p(C_2|x) > 1$. This condition can be worked out as\n",
    "$$\n",
    "\\frac{p(C_1|x)}{p(C_2|x)} = \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)} = \\frac{10 \\times 0.6}{200(x-1)\\times 0.4}>1\n",
    "$$\n",
    "which evaluates to choosing\n",
    "$$\\begin{align*}\n",
    "C_1 &\\quad \\text{ if $1.0\\leq x < 1.075$}\\\\ \n",
    "C_2 &\\quad \\text{ if $1.075 \\leq x \\leq 1.1$ }\n",
    "\\end{align*}$$\n",
    "The probability that $x$ falls outside the interval $[1.0,1.1]$ is zero.       \n",
    "> (b) The total probability of error $p(\\text{error})=\\int_x p(\\text{error}|x)p(x) \\mathrm{d}{x}$. We can work this out as\n",
    "$$\\begin{align*}\n",
    "p(\\text{error}) &= \\int_x p(\\text{error}|x)p(x)\\mathrm{d}{x}\\\\\n",
    "&= \\int_{1.0}^{1.075} p(C_2|x)p(x) \\mathrm{d}{x} + \\int_{1.075}^{1.1} p(C_1|x)p(x) \\mathrm{d}{x}\\\\\n",
    "&= \\int_{1.0}^{1.075} p(x|C_2)p(C_2) \\mathrm{d}{x} + \\int_{1.075}^{1.1} p(x|C_1)p(C_1) \\mathrm{d}{x}\\\\\n",
    "&= \\int_{1.0}^{1.075}0.4\\cdot 200(x-1) \\mathrm{d}{x} + \\int_{1.075}^{1.1} 0.6\\cdot 10 \\mathrm{d}{x}\\\\\n",
    "&=80\\cdot[x^2/2-x]_{1.0}^{1.075} + 6\\cdot[x]_{1.075}^{1.1}\\\\\n",
    "&=0.225 + 0.15\\\\\n",
    "&=0.375\n",
    "\\end{align*}$$\n",
    "\n",
    "- Describe shortly in your own words the similarities and differences between the discriminative and generative approach to classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discriminative Classification\n",
    "\n",
    "1.  Given a data set $D=\\{(x_1,y_1),\\ldots,(x_N,y_N)\\}$, where $x_n \\in \\mathbb{R}^M$ and $y_n \\in \\{0,1\\}$. The probabilistic classification method known as *logistic regression* attempts to model these data as\n",
    "$$p(y_n=1|x_n) = \\sigma(\\theta^T x_n + b)$$\n",
    "where $\\sigma(x) = 1/(1+e^{-x})$ is the *logistic function*. Let's introduce shorthand notation $\\mu_n=\\sigma(\\theta^T x_n + b)$. So, for every input $x_n$, we have a model output $\\mu_n$ and an actual data output $y_n$.                   \n",
    "  (a) Express $p(y_n|x_n)$ as a Bernoulli distribution in terms of $\\mu_n$ and $y_n$.         \n",
    "  (b) If furthermore is given that the data set is IID, show that the log-likelihood is given by\n",
    "$$\n",
    "L(\\theta) \\triangleq \\log p(D|\\theta) = \\sum_n \\left\\{y_n \\log \\mu_n  + (1-y_n)\\log(1-\\mu_n)\\right\\}\n",
    "$$        \n",
    "  (c) Prove that the derivative of the logistic function is given by\n",
    "$$\n",
    "\\sigma^\\prime(\\xi) = \\sigma(\\xi)\\cdot\\left(1-\\sigma(\\xi)\\right)\n",
    "$$              \n",
    "  (d) Show that the derivative of the log-likelihood is\n",
    "$$\n",
    "\\nabla_\\theta L(\\theta) = \\sum_{n=1}^N \\left( y_n - \\sigma(\\theta^T x_n +b)\\right)x_n\n",
    "$$               \n",
    "  (e) Design a gradient-ascent algorithm for maximizing $L(\\theta)$ with respect to $\\theta$.     \n",
    "  (f) Interpret this result.\n",
    ">  (a) $p(y_n|x_n) = p(y_n=1|x_n)^{y_n} p(y_n=0|x_n)^{1-y_n} = \\mu_n^{y_n}(1-\\mu_n)^{1-y_n}$               \n",
    ">  (b) The log-likelihood is given by\n",
    "$$\\begin{align*} L(\\theta) &= \\log p(D|\\theta) = \\sum_n \\log p(y_n|x_n,\\theta)\\\\\n",
    "&= \\sum_n \\left\\{y_n \\log \\mu + (1-y_n)\\log(1-\\mu_n)\\right\\}\n",
    "\\end{align*}$$               \n",
    ">  (c) $$\\begin{align*}\n",
    "\\frac{d{}}{d{\\xi}}\\left( \\frac{1}{1+e^{-\\xi}}\\right) &= \\frac{(1+e^{-\\xi})\\cdot 0 - (-e^{-\\xi}\\cdot 1)}{(1+e^{-\\xi})^2}\\\\\n",
    "&= \\frac{e^{-\\xi}}{(1+e^{-\\xi})^2} = \\frac{1}{1+e^{-\\xi}}\\cdot \\frac{e^{-\\xi}}{1+e^{-\\xi}}\\\\\n",
    "&=\\sigma(\\xi)\\left( 1-\\sigma(\\xi)\\right)\n",
    "\\end{align*}$$              \n",
    ">  (d)\n",
    "$$\\begin{align*}\n",
    "\\nabla_\\theta L(\\theta) &= \\sum_n \\left(\\frac{y_n}{\\mu_n} - \\frac{1-y_n}{1-\\mu_n} \\right) \\cdot \\frac{\\partial{\\mu_n}}{\\partial{(\\theta^T x_n +b)}} \\cdot \\frac{\\partial{(\\theta^T x_n +b)}}{\\partial{\\theta}}\\\\\n",
    "&= \\sum_n \\frac{y_n - \\mu_n}{\\mu_n(1-\\mu_n)} \\cdot \\mu_n(1-\\mu_n) \\cdot x_n\\\\\n",
    "&= \\sum_n (y_n - \\mu_n) \\cdot x_n\n",
    "\\end{align*}$$              \n",
    ">  (e)\n",
    "$$ \\theta^{(t+1)} = \\theta^{(t)} + \\rho \\sum_n (y_n - \\mu_n^{(t)})x_n$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Latent Variable Models and Variational Bayes\n",
    "\n",
    "1. Given the free energy functional $\n",
    "F[q] = \\sum_z q(z) \\log \\frac{q(z)}{p(x,z)}$, proof the [EE, DE and AC decompositions](#fe-decompositions). \n",
    "\n",
    "2. Bishop exercise 9.3\n",
    "\n",
    "- Unfortunately, the KL functional is not computable in this form because it contains the Bayesian posterior $p(z|x)$ to which we have no access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Factor Graphs\n",
    "\n",
    "\n",
    " - <span class=\"exercise\">(Exercise) Derive now that the message coming from the open end of a half-edge always equals $1$.</span> \n",
    " \n",
    " - <span class=\"exercise\">(Exercise) Verfiy for yourself that all maginals in a cycle-free graph (a tree) can be computed exactly by starting with messages at the terminals and working towards the root of the tree.</span>\n",
    " \n",
    " - (Ex.1) Reflect on the fact that we now have methods for both marginalization and processing observations in FFGs. In principle, we are sufficiently equipped to do inference in probabilistic models through message passing. Draw the graph for $$p(x_1,x_2,x_3)=f_a(x_1)\\cdot f_b(x_1,x_2)\\cdot f_c(x_2,x_3)$$ and show which boxes need to be closed for computing $p(x_1|x_2)$.\n",
    " \n",
    " - (Ex.2) Consider a variable $X$ with measurements $D=\\{x_1,x_2\\}$. We assume the following model for $X$:\n",
    "$$\\begin{align*}\n",
    "p(D,\\theta) &= p(\\theta)\\cdot \\prod_{n=1}^2 p(x_n|\\theta)  \\\\\n",
    "p(\\theta) &= \\mathcal{N}(\\theta \\mid 0,1) \\\\\n",
    "p(x_n \\mid\\theta) &= \\mathcal{N}(x_n \\mid \\theta,1)\n",
    "\\end{align*}$$\n",
    "  - Draw the factor graph and infer $\\theta$ through the Sum-Product Algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dynamic Models\n",
    "\n",
    "1. (a) What is the 1st-order Markov assumption?      \n",
    "(b) Derive the joint probability distribution $p(x_{1:T},z_{0:T})$ (where $x_t$ and $z_t$ are observed and latent variables respectively) for the state-space model with transition and observation models $p(z_t|z_{t-1})$ and $p(x_t|z_t)$.      \n",
    "(c) What is a Hidden Markov Model (HMM)?       \n",
    "(d) What is a Linear Dynamical System (LDS)?      \n",
    "(e) What is a Kalman Filter?      \n",
    "(f) How does the Kalman Filter relate to the LDS?       \n",
    "(g) Explain the popularity of Kalman filtering and HMMs?       \n",
    "(h) How relates a HMM to a GMM? \n",
    "> (a) An auto-regressive model is first-order Markov if $$p(x_t|x_{t-1},x_{t-1},\\ldots,x_1) = p(x_t|x_{t-1})\\,.$$              \n",
    "> (b) $$p(x_{1:T},z_{0:T}) = p(z_0)\\prod_{t=1}^Tp(z_t|z_{t-1}) \\prod_{t=1}^T p(x_t|z_t)$$               \n",
    "> (c)  A HMM is a state-space model (as described in (b)) where the latent variable $z_t$ is discretely valued. Iow, the HMM has hidden clusters.            \n",
    "> (d)  An LDS is a state-space model (also described by the eq in (b)), but now the latent variable $z_t$ is continuously valued.     \n",
    "> (e) A Kalman filter is a recursive solution to the inference problem $p(z_t|x_t,x_{t-1},\\dots,x_1)$, based on a state estimate at the previous time step $p(z_{t-1}|x_{t-1},x_{t-2},\\dots,x_1)$  and a new observation $x_t$. Basically, it's a recursive filter that updates the optimal Bayesian estimate of the current state $z_t$ based on all past observations $x_t,x_{t-1},\\dots,x_1$.     \n",
    "> (f) The LDS describes a (generative) *model*. The Kalman filter does not describe a model, but rather describes an *inference task* on the LDS model.           \n",
    "> (g) The LDS and HMM models are both quite general and flexible generative probabilistic models for time series. There exists very efficient algorithms for executing the latent state inference tasks (Kalman filter for LDS and there is a similar algorithm for the HMM). That makes these models flexible and practical. Hence the popularity of these models.            \n",
    "> (h) An HMM can be interpreted as a Gaussian-Mixture-model-over-time. \n",
    "\n",
    "- Show that in a Markovian state-space model, the observation sequence $x^T$ is not a first-order Markov chain, i.e., show that for the model\n",
    "    $$\\begin{align*}\n",
    " p(x^T,z^T) &= p(z_1) \\prod_{t=2}^T p(z_t\\,|\\,z_{t-1})\\,\\prod_{t=1}^T p(x_t\\,|\\,z_t)\n",
    "\\end{align*}$$\n",
    "the following statement holds: \n",
    "    $$p(x_t\\,|\\,x_{t-1},x_{t-2}) \\neq p(x_t\\,|\\,x_{t-1})\\,.$$\n",
    "In other words, the latent variables $z_t$ represent a memory bank for past observations beyond $t-1$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intelligent Agents and Active Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<!--- end of lesson ---> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\r\n",
       "This HTML file contains custom styles and some javascript.\r\n",
       "Include it a Jupyter notebook for improved rendering.\r\n",
       "-->\r\n",
       "\r\n",
       "<!-- Fonts -->\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\r\n",
       "\r\n",
       "<!-- Custom style -->\r\n",
       "<style>\r\n",
       "\r\n",
       "@font-face {\r\n",
       "    font-family: \"Computer Modern\";\r\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\r\n",
       "}\r\n",
       "\r\n",
       "#notebook_panel { /* main background */\r\n",
       "    background: rgb(245,245,245);\r\n",
       "}\r\n",
       "\r\n",
       "div.container {\r\n",
       "    min-width: 960px;\r\n",
       "}\r\n",
       "\r\n",
       "div #notebook { /* centre the content */\r\n",
       "    background: #fff; /* white background for content */\r\n",
       "    margin: auto;\r\n",
       "    padding-left: 0em;\r\n",
       "}\r\n",
       "\r\n",
       "#notebook li { /* More space between bullet points */\r\n",
       "    margin-top:0.8em;\r\n",
       "}\r\n",
       "\r\n",
       "/* draw border around running cells */\r\n",
       "div.cell.border-box-sizing.code_cell.running {\r\n",
       "    border: 1px solid #111;\r\n",
       "}\r\n",
       "\r\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\r\n",
       "div.cell.code_cell {\r\n",
       "    background-color: rgb(256,256,256);\r\n",
       "    border-radius: 0px;\r\n",
       "    padding: 0.5em;\r\n",
       "    margin-left:1em;\r\n",
       "    margin-top: 1em;\r\n",
       "}\r\n",
       "\r\n",
       "div.text_cell_render{\r\n",
       "    font-family: 'Alegreya Sans' sans-serif;\r\n",
       "    line-height: 140%;\r\n",
       "    font-size: 125%;\r\n",
       "    font-weight: 400;\r\n",
       "    width:800px;\r\n",
       "    margin-left:auto;\r\n",
       "    margin-right:auto;\r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "/* Formatting for header cells */\r\n",
       ".text_cell_render h1 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-style:regular;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 45pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0,51,102);\r\n",
       "    margin-bottom: 0.5em;\r\n",
       "    margin-top: 0.5em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h2 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 30pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0,51,102);\r\n",
       "    margin-bottom: 0.1em;\r\n",
       "    margin-top: 0.3em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h3 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    margin-top:16px;\r\n",
       "    font-size: 22pt;\r\n",
       "    font-weight: 600;\r\n",
       "    margin-bottom: 3px;\r\n",
       "    font-style: regular;\r\n",
       "    color: rgb(102,102,0);\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h4 {    /*Use this for captions*/\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-size: 14pt;\r\n",
       "    text-align: center;\r\n",
       "    margin-top: 0em;\r\n",
       "    margin-bottom: 2em;\r\n",
       "    font-style: regular;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\r\n",
       "    font-family: 'Nixie One', sans-serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 16pt;\r\n",
       "    color: rgb(163,0,0);\r\n",
       "    font-style: italic;\r\n",
       "    margin-bottom: .1em;\r\n",
       "    margin-top: 0.8em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h6 { /*use this for copyright note*/\r\n",
       "    font-family: 'PT Mono', sans-serif;\r\n",
       "    font-weight: 300;\r\n",
       "    font-size: 9pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: grey;\r\n",
       "    margin-bottom: 1px;\r\n",
       "    margin-top: 1px;\r\n",
       "}\r\n",
       "\r\n",
       ".CodeMirror{\r\n",
       "    font-family: \"PT Mono\";\r\n",
       "    font-size: 90%;\r\n",
       "}\r\n",
       "\r\n",
       ".boxed { /* draw a border around a piece of text */\r\n",
       "  border: 1px solid blue ;\r\n",
       "}\r\n",
       "\r\n",
       "h4#CODE-EXAMPLE,\r\n",
       "h4#END-OF-CODE-EXAMPLE {\r\n",
       "    margin: 10px 0;\r\n",
       "    padding: 10px;\r\n",
       "    background-color: #d0f9ca !important;\r\n",
       "    border-top: #849f81 1px solid;\r\n",
       "    border-bottom: #849f81 1px solid;\r\n",
       "}\r\n",
       "\r\n",
       ".emphasis {\r\n",
       "    color: red;\r\n",
       "}\r\n",
       "\r\n",
       ".exercise {\r\n",
       "    color: green;\r\n",
       "}\r\n",
       "\r\n",
       ".proof {\r\n",
       "    color: blue;\r\n",
       "}\r\n",
       "\r\n",
       "code {\r\n",
       "  padding: 2px 4px !important;\r\n",
       "  font-size: 90% !important;\r\n",
       "  color: #222 !important;\r\n",
       "  background-color: #efefef !important;\r\n",
       "  border-radius: 2px !important;\r\n",
       "}\r\n",
       "\r\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\r\n",
       "   as they will be removed through some other method */\r\n",
       "@media not print {\r\n",
       "  .cell:nth-last-child(-n+2) {\r\n",
       "    display: none;\r\n",
       "  }\r\n",
       "}\r\n",
       "\r\n",
       "footer.hidden-print {\r\n",
       "    display: none !important;\r\n",
       "}\r\n",
       "    \r\n",
       "</style>\r\n",
       "\r\n",
       "<!-- MathJax styling -->\r\n",
       "<script>\r\n",
       "    MathJax.Hub.Config({\r\n",
       "                        TeX: {\r\n",
       "                           extensions: [\"AMSmath.js\"],\r\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\r\n",
       "                           },\r\n",
       "                tex2jax: {\r\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\r\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\r\n",
       "                },\r\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\r\n",
       "                \"HTML-CSS\": {\r\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\r\n",
       "                }\r\n",
       "        });\r\n",
       "</script>\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f\n",
    "    display(\"text/html\", read(f,String))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
