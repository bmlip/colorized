{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability Theory Review"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Review of Probability Theory as a theory for rational/logical reasoning with uncertainties (i.e., a Bayesian interpretation)\n",
    "- Materials        \n",
    "  - Mandatory\n",
    "    - These lecture notes\n",
    "  - Optional\n",
    "    - Bishop pp. 12-24\n",
    "    - [Ariel Caticha - 2012 - Entropic Inference and the Foundations of Physics](https://github.com/bertdv/BMLIP/blob/master/lessons/notebooks/files/Caticha-2012-Entropic-Inference-and-the-Foundations-of-Physics.pdf), pp.7-56 (ch.2: probability)\n",
    "      - Great introduction to probability theory, in particular w.r.t. its correct interpretation as a state-of-knowledge.\n",
    "      - Absolutely worth your time to read the whole chapter (even if you skip section 2.2.4: Cox's proof (pp.15-18).))\n",
    "    - [Edwin Jaynes - 2003 - Probability Theory -- The Logic of Science](http://www.med.mcgill.ca/epidemiology/hanley/bios601/GaussianModel/JaynesProbabilityTheory.pdf). \n",
    "      - Brilliant book on Bayesian view on probability theory. Just for fun, scan the annotated bibliography and references.\n",
    "    - [D.S. Sivia, with J. Skilling - 2006 - Data Analysis: A Bayesian Tutorial](https://www.amazon.com/Data-Analysis-Bayesian-Devinderjit-Sivia/dp/0198568320)\n",
    "      - Very nice and correct introduction to Bayesian data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Analysis: A Bayesian Tutorial](https://www.amazon.com/Data-Analysis-Bayesian-Devinderjit-Sivia/dp/0198568320)\n",
    "\n",
    "- The following is an excerpt from the book [Data Analysis: A Bayesian Tutorial](https://www.amazon.com/Data-Analysis-Bayesian-Devinderjit-Sivia/dp/0198568320)\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"./figures/preface-data-analysis-a-Bayesian-tutorial.png\" width=\"600px\"></p>\n",
    "\n",
    "- Does this fragment resonate with your own experience? \n",
    "\n",
    "- In this lesson we introduce *Probability Theory* (PT) again. As we will see in the next lessons, PT is all you need to make sense of machine learning, artificial intelligence, statistics, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Problem: Disease Diagnosis\n",
    "\n",
    "- **Problem**: Given a disease with prevalence of  1%  and a test procedure  with sensitivity ('true positive' rate) of  95%  and specificity ('true negative' rate) of  85% , what is the chance that somebody who tests positive actually has the disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Use probabilistic inference, to be discussed in this lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Design of Probability Theory\n",
    "\n",
    "- Define an **event** (or \"proposition\") $A$ as a statement, whose truth can be contemplated by a person, e.g., \n",
    "\n",
    "$$ùê¥= \\texttt{'there is life on Mars'}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we assume the fact $$I = \\texttt{'All known life forms require water'}$$ and a new piece of information $$x = \\texttt{'There is water on Mars'}$$ becomes available, how _should_ our degree of belief in event $A$ be affected (if we were rational)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [Richard T. Cox, 1946](https://aapt.scitation.org/doi/10.1119/1.1990764) developed a **calculus for rational reasoning** about how to represent and update the degree of _beliefs_ about the truth value of events when faced with new information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In developing this calculus, only some very agreeable assumptions were made, e.g.,\n",
    "  - (Representation). Degrees of rational belief (or, as we shall later call them, probabilities) are represented by real numbers.\n",
    "  - (Transitivity). If the belief in $A$ is greater than the belief in $B$, and the belief in $B$ is greater than the belief in $C$, then the belief in $A$ must be greater than the belief in $C$.\n",
    "  - (Consistency). If the belief in an event can be inferred in two different ways, then the two ways must agree on the resulting belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- This effort resulted in confirming that the [sum and product rules of Probability Theory](#PT-calculus) are the **only** proper rational way to process belief intensities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\Rightarrow$ Probability theory (PT) provides _the_ **theory of optimal processing of incomplete information** (see [Cox theorem](https://en.wikipedia.org/wiki/Cox%27s_theorem), and [Caticha](https://github.com/bertdv/BMLIP/blob/master/lessons/notebooks/files/Caticha-2012-Entropic-Inference-and-the-Foundations-of-Physics.pdf), pp.7-24), and as such provides the (only) proper quantitative framework for drawing conclusions from a finite (read: incomplete) data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why Probability Theory for Machine Learning?\n",
    "\n",
    "- Machine learning concerns drawing conclusions about model parameter settings from (a finite set of) data and therefore PT provides the _optimal calculus for machine learning_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In general, nearly all interesting questions in machine learning can be stated in the following form (a conditional probability):\n",
    "\n",
    "$$p(\\texttt{whatever-we-want-to-know}\\, | \\,\\texttt{whatever-we-do-know})$$\n",
    "\n",
    "where $p(a|b)$ means the probability that $a$ is true, given that $b$ is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Examples\n",
    "  - Predictions\n",
    "  $$p(\\,\\texttt{future-observations}\\,|\\,\\texttt{past-observations}\\,)$$\n",
    "  - Classify a received data point $x$ \n",
    "  $$p(\\,x\\texttt{-belongs-to-class-}k \\,|\\,x\\,)$$\n",
    "  - Update a model based on a new observation\n",
    "   $$p(\\,\\texttt{model-parameters} \\,|\\,\\texttt{new-observation},\\,\\texttt{past-observations}\\,)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Frequentist vs. Bayesian Interpretation of Probabilities\n",
    "\n",
    "- The interpretation of a probability as a **degree-of-belief** about the truth value of an event is also called the **Bayesian** interpretation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the **Bayesian** interpretation, the probability is associated with a **state-of-knowledge** (usually held by a person, but formally by a rational agent). \n",
    "  - For instance, in a coin tossing experiment, $p(\\texttt{tail}) = 0.4$ should be interpreted as the belief that there is a 40% chance that $\\texttt{tail}$ comes up if the coin were tossed.\n",
    "  - Under the Bayesian interpretation, PT calculus (sum and product rules) **extends boolean logic to rational reasoning with uncertainty**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The Bayesian interpretation contrasts with the **frequentist** interpretation of a probability as the relative frequency that an event would occur under repeated execution of an experiment.\n",
    "\n",
    "  - For instance, if the experiment is tossing a coin, then $p(\\texttt{tail}) = 0.4$ means that in the limit of a large number of coin tosses, 40% of outcomes turn up as $\\texttt{tail}$.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The Bayesian viewpoint is more generally applicable than the frequentist viewpoint, e.g., it is hard to apply the frequentist viewpoint to events like '$\\texttt{it will rain tomorrow}$'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The Bayesian viewpoint is clearly favored in the machine learning community. (In this class, we also strongly favor the Bayesian interpretation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most likely, in the past you learned the frequentist interpretation of probabilities. It is a primary goal of this class to convert you to the Bayesian interpretation since it is far more potent than the frequentist interpretation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aubrey Clayton, in his wonderful book [Bernoulli's fallacy](https://aubreyclayton.com/bernoulli) (2021) writes about this issue: \n",
    "  > ‚ÄúCompared with Bayesian methods, standard [frequentist] statistical techniques use only a small fraction of the available information about a research hypothesis (how well it predicts some observation), so naturally they will struggle when that limited information proves inadequate. Using standard statistical methods is like driving a car at night on a poorly lit highway: to keep from going in a ditch, we could build an elaborate system of bumpers and guardrails and equip the car with lane departure warnings and sophisticated navigation systems, and even then we could at best only drive to a few destinations. Or we could turn on the headlights.‚Äù "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probability Theory Notation\n",
    "\n",
    "##### events\n",
    "-  Define an **event** $A$ as a statement, whose truth can be contemplated by a person, e.g.,\n",
    "\n",
    "$$A = \\text{'it will rain tomorrow'}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We write the denial of $A$, i.e. the event **not**-A, as $\\bar{A}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given two events $A$ and $B$, we write the **conjunction** \"$A \\wedge B$\" as \"$A,B$\" or \"$AB$\". The conjunction $AB$ is true only if both $A$ and $B$ are true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We will write the **disjunction** \"$A \\lor B$\" as \"$A + B$\", which is true if either $A$ or $B$ is true or both $A$ and $B$ are true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that, if $X$ is a variable, then an assignment $X=x$ (with $x$ a value, e.g., $X=5$) can be interpreted as an event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### probabilities\n",
    "\n",
    "- For any event $A$, with background knowledge $I$, the **conditional probability of $A$ given $I$**, is written as \n",
    "$$p(A|I)\\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- All probabilities are in principle conditional probabilities of the type $p(A|I)$, since there is always some background knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Unfortunately, PT notation is usually rather sloppy :(\n",
    "\n",
    "- We often write $p(A)$ rather than $p(A|I)$ if the background knowledge $I$ is assumed to be obviously present. E.g., $p(A)$ rather than $p(\\,A\\,|\\,\\text{the-sun-comes-up-tomorrow}\\,)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- (In the context of variable assignments) we often write $p(x)$ rather than $p(X=x)$, assuming that the reader understands the context.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In an apparent effort to further abuse notational conventions, $p(X)$ denotes the full distribution over variable $X$, i.e., the distribution for all assignments for $X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $X$ is a *discretely* valued variable, then $p(X=x)$ is a probability *mass* function (PMF) with $0\\le p(X=x)\\le 1$ and normalization $\\sum_x p(x) =1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $X$ is *continuously* valued, then $p(X=x)$ is a probability *density* function (PDF) with $p(X=x)\\ge 0$  and normalization $\\int_x p(x)\\mathrm{d}x=1$. \n",
    "  - Note that if $X$ is continuously valued, then the value of the PDF $p(x)$ is not necessarily $\\le 1$. E.g., a uniform distribution on the continuous domain $[0,.5]$ has value $p(x) = 2$.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Often, we do not bother to specify if $p(x)$ refers to a continuous or discrete variable.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a id=\"PT-calculus\">Probability Theory Calculus</a>\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let $p(A|I)$ indicate the belief in event $A$, given that $I$ is true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The following product and sum rules are also known as the **axioms of probability theory**, but as discussed above, under some mild assumptions, they can be derived as the unique rules for *rational reasoning under uncertainty* ([Cox theorem, 1946](https://en.wikipedia.org/wiki/Cox%27s_theorem), and [Caticha, 2012](https://github.com/bertdv/BMLIP/blob/master/lessons/notebooks/files/Caticha-2012-Entropic-Inference-and-the-Foundations-of-Physics.pdf), pp.7-26)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Sum rule**. The disjunction for two events $A$ and $B$ given background $I$ is given by\n",
    "$$ \\boxed{p(A+B|I) = p(A|I) + p(B|I) - p(A,B|I)}$$\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Product rule**. The conjuction of two events $A$ and $B$ with given background $I$ is given by \n",
    "$$ \\boxed{p(A,B|I) = p(A|B,I)\\,p(B|I)}$$\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **All legitimate probabilistic relations can be derived from the sum and product rules!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independent and Mutually Exclusive Events\n",
    "\n",
    "- Two events $A$ and $B$ are said to be **independent** if the probability of one is not altered by information about the truth of the other, i.e., $p(A|B) = p(A)$\n",
    "  - $\\Rightarrow$ If $A$ and $B$ are independent, given $I$, then the product rule simplifies to $$p(A,B|I) = p(A|I) p(B|I)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Two events $A_1$ and $A_2$ are said to be **mutually exclusive** if they cannot be true simultanously, i.e., if $p(A_1,A_2)=0$.\n",
    "  - $\\Rightarrow$ For mutually exclusive events, the sum rule simplifies to\n",
    "  $$p(A_1+A_2) = p(A_1) + p(A_2)$$\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A set of events $A_1, A_2, \\ldots, A_N$ is said to be **collectively exhaustive** if one of the statements is necessarily true, i.e., $A_1+A_2+\\cdots +A_N=\\mathrm{TRUE}$, or equivalently \n",
    "$$p(A_1+A_2+\\cdots +A_N)=1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that, if $A_1, A_2, \\ldots, A_n$ are both **mutually exclusive** and **collectively exhausitive** (MECE) events, then\n",
    "    $$\\sum_{n=1}^N p(A_n) = p(A_1 + \\ldots + A_N) = 1$$\n",
    "    - More generally, if $\\{A_n\\}$ are MECE events, then $\\sum_{n=1}^N p(A_n,B) = p(B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Sum Rule and Marginalization\n",
    "\n",
    "- We mentioned that every inference problem in PT can be evaluated through the sum and product rules. Next, we present two useful corollaries: (1) _Marginalization_ and (2) _Bayes rule_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $X \\in \\mathcal{X}$ and $Y \\in \\mathcal{Y}$ are variables over finite domains, then it follows from the above considerations about MECE events that \n",
    "$$\n",
    "\\sum_{Y\\in \\mathcal{Y}} p(X,Y) = p(X) \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Summing $Y$ out of a joint distribution $p(X,Y)$ is called **marginalization** and the result $p(X)$ is sometimes referred to as the **marginal probability**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that this is just a **generalized sum rule**. In fact, Bishop (p.14) (and some other authors as well) calls this the sum rule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Of course, in the continuous domain, the (generalized) sum rule becomes\n",
    "$$p(X)=\\int p(X,Y) \\,\\mathrm{d}Y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a id=\"Bayes-rule\">The Product Rule and Bayes Rule</a>\n",
    "\n",
    "- Consider two variables $D$ and $\\theta$; it follows from symmetry arguments that \n",
    "$$p(D,\\theta)=p(D|\\theta)p(\\theta)=p(\\theta|D)p(D)$$ \n",
    "and hence that\n",
    "$$ p(\\theta|D) = \\frac{p(D|\\theta) }{p(D)}p(\\theta)\\,.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This formula is called **Bayes rule** (or Bayes theorem). While Bayes rule is always true, a particularly useful application occurs when $D$ refers to an observed data set and $\\theta$ is set of model parameters. In that case,\n",
    "\n",
    "  - the **prior** probability $p(\\theta)$ represents our **state-of-knowledge** about proper values for $\\theta$, before seeing the data $D$.\n",
    "  - the **posterior** probability $p(\\theta|D)$ represents our state-of-knowledge about $\\theta$ after we have seen the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\Rightarrow$ Bayes rule tells us how to update our knowledge about model parameters when facing new data. Hence, \n",
    "\n",
    "<center>\n",
    "<div style=\"font-size:large; color:red\">\n",
    "Bayes rule is the fundamental rule for learning from data!\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes Rule Nomenclature\n",
    "- Some nomenclature associated with Bayes rule:\n",
    "$$\n",
    "\\underbrace{p(\\theta | D)}_{\\text{posterior}} = \\frac{\\overbrace{p(D|\\theta)}^{\\text{likelihood}} \\times \\overbrace{p(\\theta)}^{\\text{prior}}}{\\underbrace{p(D)}_{\\text{evidence}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the evidence (a.k.a. _marginal likelihood_ ) can be computed from the numerator through marginalization since\n",
    "$$ p(D) = \\int p(D,\\theta) \\,\\mathrm{d}\\theta = \\int p(D|\\theta)\\,p(\\theta) \\,\\mathrm{d}\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Hence, having access to likelihood and prior is in principle sufficient to compute both the evidence and the posterior. To emphasize that point, Bayes rule is sometimes written as a transformation:\n",
    "\n",
    "$$ \\underbrace{\\underbrace{p(\\theta|D)}_{\\text{posterior}}\\cdot \\underbrace{p(D)}_{\\text{evidence}}}_{\\text{this is what we want to compute}} = \\underbrace{\\underbrace{p(D|\\theta)}_{\\text{likelihood}}\\cdot \\underbrace{p(\\theta)}_{\\text{prior}}}_{\\text{this is available}}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For a given data set $D$, the posterior probabilities of the parameters scale relatively against each other as\n",
    "\n",
    "$$\n",
    "p(\\theta|D) \\propto p(D|\\theta) p(\\theta)\n",
    "$$\n",
    "\n",
    "- $\\Rightarrow$ All that we can learn from the observed data is contained in the likelihood function $p(D|\\theta)$. This is called the **likelihood principle**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Likelihood Function vs the Sampling Distribution\n",
    "\n",
    "- Consider a distribution $p(D|\\theta)$, where $D$ relates to variables that are observed (i.e., a \"data set\") and $\\theta$ are model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In general, $p(D|\\theta)$ is just a function of the two variables $D$ and $\\theta$. We distinguish two interpretations of this function, depending on which variable is observed (or given by other means). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  The **sampling distribution** (a.k.a. the **data-generating** distribution) $$p(D|\\theta=\\theta_0)$$ (which is a function of $D$ only) describes a probability distribution for data $D$, assuming that it is generated by the given model with parameters fixed at $\\theta = \\theta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In a machine learning context, often the data is observed, and $\\theta$ is the free variable. In that case, for given observations $D=D_0$, the **likelihood function** (which is a function only of the model parameters $\\theta$) is defined as $$\\mathrm{L}(\\theta) \\triangleq p(D=D_0|\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that $\\mathrm{L}(\\theta)$ is not a probability distribution for $\\theta$ since in general $\\sum_\\theta \\mathrm{L}(\\theta) \\neq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code Example: Sampling Distribution and Likelihood Function for the Coin Toss\n",
    "\n",
    "Consider the following simple model for the outcome (head or tail) $y \\in \\{0,1\\}$ of a biased coin toss with parameter $\\theta \\in [0,1]$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(y|\\theta) &\\triangleq \\theta^y (1-\\theta)^{1-y}\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "We can plot both the sampling distribution $p(y|\\theta=0.8)$ and the likelihood function $L(\\theta) = p(y=0|\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 2 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using PyPlot\n",
    "#using Plots\n",
    "p(y,Œ∏) = Œ∏.^y .* (1 .- Œ∏).^(1 .- y)\n",
    "f = figure()\n",
    "\n",
    "Œ∏ = 0.5 # Set parameter\n",
    "# Plot the sampling distribution\n",
    "subplot(221); stem([0,1], p([0,1],Œ∏)); \n",
    "title(\"Sampling distribution\");\n",
    "xlim([-0.5,1.5]); ylim([0,1]); xlabel(\"y\"); ylabel(\"p(y|Œ∏=$(Œ∏))\");\n",
    "\n",
    "subplot(222);\n",
    "_Œ∏ = 0:0.01:1\n",
    "y = 1.0 # Plot p(y=1 | Œ∏)\n",
    "plot(_Œ∏,p(y,_Œ∏))\n",
    "title(\"Likelihood function\"); \n",
    "xlabel(\"Œ∏\"); \n",
    "ylabel(\"L(Œ∏) = p(y=$y)|Œ∏)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The (discrete) sampling distribution is a valid probability distribution. \n",
    "However, the likelihood function $L(\\theta)$ clearly isn't, since $\\int_0^1 L(\\theta) \\mathrm{d}\\theta \\neq 1$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probabilistic Inference\n",
    "\n",
    "- **Probabilistic inference** refers to computing\n",
    "$$\n",
    "p(\\,\\text{whatever-we-want-to-know}\\, | \\,\\text{whatever-we-already-know}\\,)\n",
    "$$\n",
    "  - For example: \n",
    "  $$\\begin{align*}\n",
    " p(\\,\\text{Mr.S.-killed-Mrs.S.} \\;&|\\; \\text{he-has-her-blood-on-his-shirt}\\,) \\\\\n",
    " p(\\,\\text{transmitted-codeword} \\;&|\\;\\text{received-codeword}\\,) \n",
    "  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This can be accomplished by repeated application of sum and product rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In particular, consider a joint distribution $p(X,Y,Z)$. Assume we are interested in $p(X|Z)$:\n",
    "$$\\begin{align*}\n",
    "p(X|Z) \\stackrel{p}{=} \\frac{p(X,Z)}{p(Z)} \\stackrel{s}{=} \\frac{\\sum_Y p(X,Y,Z)}{\\sum_{X,Y} p(X,Y,Z)} \\,,\n",
    "\\end{align*}$$\n",
    "where the 's' and 'p' above the equality sign indicate whether the sum or product rule was used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the rest of this course, we'll encounter many long probabilistic derivations. For each manipulation, you should be able to associate an 's' (for sum rule), a 'p' (for product or Bayes rule) or an 'm' (for a simplifying model assumption) above any equality sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working out the example problem: Disease Diagnosis\n",
    "\n",
    "- **Problem**: Given a disease $D$ with prevalence of $1\\%$ and a test procedure $T$ with sensitivity ('true positive' rate) of $95\\%$ and specificity ('true negative' rate) of $85\\%$, what is the chance that somebody who tests positive actually has the disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: The given data are $p(D=1)=0.01$, $p(T=1|D=1)=0.95$ and $p(T=0|D=0)=0.85$. Then according to Bayes rule,\n",
    "\n",
    "$$\\begin{align*}\n",
    "p( D=1 &| T=1) \\\\\n",
    "&\\stackrel{p}{=} \\frac{p(T=1|D=1)p(D=1)}{p(T=1)} \\\\\n",
    "&\\stackrel{s}{=} \\frac{p(T=1|D=1)p(D=1)}{p(T=1|D=1)p(D=1)+p(T=1|D=0)p(D=0)} \\\\\n",
    "&= \\frac{0.95\\times0.01}{0.95\\times0.01 + 0.15\\times0.99} = 0.0601\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that $p(\\text{sick}|\\text{positive test}) = 0.06$ while $p(\\text{positive test} | \\text{sick}) = 0.95$. This is a huge difference that is sometimes called the \"medical test paradox\" or the [base rate fallacy](https://en.wikipedia.org/wiki/Base_rate_fallacy). \n",
    "\n",
    "- Many people have trouble distinguishing $p(A|B)$ from $p(B|A)$ in their heads. This has led to major negative consequences. For instance, unfounded convictions in the legal arena and even lots of unfounded conclusions in the pursuit of scientific results. See [Ioannidis (2005)](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124) and [Clayton (2021)](https://aubreyclayton.com/bernoulli)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference Exercise: Bag Counter\n",
    "\n",
    "- **Problem**:  A bag contains one ball, known to be either white or black. A white ball is put in, the bag is shaken,\n",
    " and a ball is drawn out, which proves to be white. What is now the\n",
    " chance of drawing a white ball?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Again, use Bayes and marginalization to arrive at $p(\\text{white}|\\text{data})=2/3$, see the [Exercises](https://nbviewer.org/github/bertdv/BMLIP/blob/master/lessons/exercises/Exercises-Probability-Theory-Review.ipynb) notebook.\n",
    "\n",
    "- $\\Rightarrow$ Note that probabilities describe **a person's state of knowledge** rather than a 'property of nature'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference Exercise: Causality?\n",
    "\n",
    "- **Problem**: A dark bag contains five red balls and seven green ones. (a) What is the probability of drawing a red ball on the first draw? Balls are not returned to the bag after each draw. (b) If you know that on the second draw the ball was a green one, what is now the probability of drawing a red ball on the first draw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: (a) $5/12$. (b) $5/11$, see the [Exercises](https://nbviewer.org/github/bertdv/BMLIP/blob/master/lessons/exercises/Exercises-Probability-Theory-Review.ipynb) notebook.\n",
    "\n",
    "- $\\Rightarrow$ Again, we conclude that conditional probabilities reflect **implications for a state of knowledge** rather than temporal causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Moments of the PDF\n",
    "\n",
    "- Consider a distribution $p(x)$. The **expected value** or **mean** is defined as \n",
    "$$\\mu_x = \\mathbb{E}[x] \\triangleq  \\int x \\,p(x) \\,\\mathrm{d}{x}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **variance** of $x$ is defined as \n",
    "$$\\Sigma_x \\triangleq \\mathbb{E} \\left[(x-\\mu_x)(x-\\mu_x)^T \\right]$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **covariance** matrix between _vectors_ $x$ and $y$ is defined as\n",
    "$$\\begin{align*}\n",
    "    \\Sigma_{xy} &\\triangleq \\mathbb{E}\\left[ (x-\\mu_x) (y-\\mu_y)^T \\right]\\\\\n",
    "    &= \\mathbb{E}\\left[ (x-\\mu_x) (y^T-\\mu_y^T) \\right]\\\\\n",
    "    &= \\mathbb{E}[x y^T] - \\mu_x \\mu_y^T\n",
    "\\end{align*}$$\n",
    "  - Clearly, if $x$ and $y$ are independent, then $\\Sigma_{xy} = 0$, since $\\mathbb{E}[x y^T] = \\mathbb{E}[x] \\mathbb{E}[y^T] = \\mu_x \\mu_y^T$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <a id=\"linear-transformation\">Linear Transformations</a> \n",
    "\n",
    "- Consider an arbitrary distribution $p(X)$ with mean $\\mu_x$ and variance $\\Sigma_x$ and the linear transformation $$Z = A X + b \\,.$$ \n",
    "\n",
    "- No matter the specification of $p(X)$, we can derive that (see [Exercises](https://nbviewer.org/github/bertdv/BMLIP/blob/master/lessons/exercises/Exercises-Probability-Theory-Review.ipynb) notebook)\n",
    "$$\\begin{align}\n",
    "\\mu_z &= A\\mu_x + b \\tag{SRG-3a}\\\\\n",
    "\\Sigma_z &= A\\,\\Sigma_x\\,A^T \\tag{SRG-3b}\n",
    "\\end{align}$$\n",
    "  -  (The tag (SRG-3a) refers to the corresponding eqn number in Sam Roweis [Gaussian identities](https://github.com/bertdv/BMLIP/blob/master/lessons/notebooks/files/Roweis-1999-gaussian-identities.pdf) notes.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PDF for the Sum of Two Variables\n",
    "\n",
    "\n",
    "- Given eqs SRG-3a and SRG-3b (previous cell), you should now be able to derive the following: for any distribution of variable $X$ and $Y$ and sum $Z = X+Y$ (proof by [Exercise](https://nbviewer.org/github/bertdv/BMLIP/blob/master/lessons/exercises/Exercises-Probability-Theory-Review.ipynb))\n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\mu_z &= \\mu_x + \\mu_y \\\\\n",
    "    \\Sigma_z &= \\Sigma_x + \\Sigma_y + 2\\Sigma_{xy} \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Clearly, it follows that if $X$ and $Y$ are **independent**, then\n",
    "\n",
    "$$\\Sigma_z = \\Sigma_x + \\Sigma_y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- More generally, given two **independent** variables\n",
    "$X$ and $Y$, with PDF's $p_x(x)$ and $p_y(y)$. The PDF $p_z(z)$for $Z=X+Y$ is given by the **convolution**\n",
    "\n",
    "$$\n",
    "p_z (z) = \\int_{ - \\infty }^\\infty  {p_x (x)p_y (z - x)\\,\\mathrm{d}{x}}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Proof**: Let $p_z(z)$ be the probability that $Z$ has value $z$. This occurs if $X$ has some value $x$ and at the same time $Y=z-x$, with joint probability $p_x(x)p_y(z-x)$. Since $x$ can be any value, we sum over all possible values for $x$ to get\n",
    "$\n",
    "p_z (z) = \\int_{ - \\infty }^\\infty  {p_x (x)p_y (z - x)\\,\\mathrm{d}{x}}\n",
    "$    \n",
    "  \n",
    "  - Note that $p_z(z) \\neq p_x(x) + p_y(y)\\,$ !!\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [https://en.wikipedia.org/wiki/List_of_convolutions_of_probability_distributions](https://en.wikipedia.org/wiki/List_of_convolutions_of_probability_distributions) shows how these convolutions work out for a few common probability distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In linear stochastic systems theory, the Fourier Transform of a PDF (i.e., the characteristic function) plays an important computational role. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code Example: Sum of Two Gaussian Distributed Variables\n",
    "\n",
    "- Consider the PDF of the sum of two independent Gaussian distributed $X$ and $Y$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "p_X(x) &= \\mathcal{N}(\\,x\\,|\\,\\mu_X,\\sigma_X^2\\,) \\\\ \n",
    "p_Y(y) &= \\mathcal{N}(\\,y\\,|\\,\\mu_Y,\\sigma_Y^2\\,) \n",
    "\\end{align*}$$\n",
    "\n",
    "- Let $Z = X + Y$. Performing the convolution (nice exercise) yields a Gaussian PDF for $Z$: \n",
    "\n",
    "$$\n",
    "p_Z(z) = \\mathcal{N}(\\,z\\,|\\,\\mu_X+\\mu_Y,\\sigma_X^2+\\sigma_Y^2\\,).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot, Distributions\n",
    "Œºx = 2.\n",
    "œÉx = 1.\n",
    "Œºy = 2.\n",
    "œÉy = 0.5\n",
    "Œºz = Œºx+Œºy; œÉz = sqrt(œÉx^2 + œÉy^2)\n",
    "x = Normal(Œºx, œÉx)\n",
    "y = Normal(Œºy, œÉy)\n",
    "z = Normal(Œºz, œÉz)\n",
    "range_min = minimum([Œºx-2*œÉx, Œºy-2*œÉy, Œºz-2*œÉz])\n",
    "range_max = maximum([Œºx+2*œÉx, Œºy+2*œÉy, Œºz+2*œÉz])\n",
    "range_grid = range(range_min, stop=range_max, length=100)\n",
    "plot(range_grid, pdf.(x,range_grid), \"k-\")\n",
    "plot(range_grid, pdf.(y,range_grid), \"b-\")\n",
    "plot(range_grid, pdf.(z,range_grid), \"r-\")\n",
    "legend([L\"p_X\", L\"p_Y\", L\"p_Z\"])\n",
    "grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PDF for the Product of Two Variables\n",
    "\n",
    "- For two continuous **independent** variables\n",
    "$X$ and $Y$, with PDF's $p_x(x)$ and $p_y(y)$, the PDF of \n",
    "$Z = X Y $ is given by \n",
    "$$\n",
    "p_z(z) = \\int_{-\\infty}^{\\infty} p_x(x) \\,p_y(z/x)\\, \\frac{1}{|x|}\\,\\mathrm{d}x\n",
    "$$\n",
    "\n",
    "- For proof, see [https://en.wikipedia.org/wiki/Product_distribution](https://en.wikipedia.org/wiki/Product_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generally, this integral does not lead to an analytical expression for $p_z(z)$. For example, [**the product of two independent variables that are both normally (Gaussian) distributed does not lead to a normal distribution**](https://nbviewer.jupyter.org/github/bertdv/BMLIP/blob/master/lessons/notebooks/The-Gaussian-Distribution.ipynb#product-of-gaussians).\n",
    "  - Exception: the distribution of the product of two variables that both have [log-normal distributions](https://en.wikipedia.org/wiki/Log-normal_distribution) is again a lognormal distribution.\n",
    "    - (If $X$ has a normal distribution, then $Y=\\exp(X)$ has a log-normal distribution.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variable Transformations\n",
    "\n",
    "- Suppose $x$ is a **discrete** variable with probability **mass** function $P_x(x)$, and $y = h(x)$ is a one-to-one function with $x = g(y) = h^{-1}(y)$. Then\n",
    "\n",
    "$$\n",
    "P_y(y) = P_x(g(y))\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Proof**: $P_y(\\hat{y}) = P(y=\\hat{y}) = P(h(x)=\\hat{y}) = P(x=g(\\hat{y})) = P_x(g(\\hat{y})). \\,\\square$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $x$ is defined on a **continuous** domain, and $p_x(x)$ is a probability **density** function, then probability mass is represented by the area under a (density) curve. Let $a=g(c)$ and $b=g(d)$. Then\n",
    "$$\\begin{align*}\n",
    "P(a ‚â§ x ‚â§ b) &= \\int_a^b p_x(x)\\mathrm{d}x \\\\\n",
    "  &= \\int_{g(c)}^{g(d)} p_x(x)\\mathrm{d}x \\\\\n",
    "  &= \\int_c^d p_x(g(y))\\mathrm{d}g(y) \\\\\n",
    "  &= \\int_c^d \\underbrace{p_x(g(y)) g^\\prime(y)}_{p_y(y)}\\mathrm{d}y \\\\  \n",
    "  &= P(c ‚â§ y ‚â§ d)\n",
    "\\end{align*}$$\n",
    "\n",
    "- Equating the two probability masses leads to identificaiton of the relation \n",
    "$$p_y(y) = p_x(g(y)) g^\\prime(y)\\,,$$ \n",
    "which is also known as the [Change-of-Variable theorem](https://en.wikipedia.org/wiki/Probability_density_function#Function_of_random_variables_and_change_of_variables_in_the_probability_density_function). \n",
    "\n",
    "- If the tranformation $y = h(x)$ is not invertible, then $x=g(y)$ does not exist. In that case, you can still work out the transformation by equating equivalent probability masses in the two domains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Transformation of a Gaussian Variable\n",
    "\n",
    "- Let $p_x(x) = \\mathcal{N}(x|\\mu,\\sigma^2)$ and $y = \\frac{x-\\mu}{\\sigma}$. \n",
    "\n",
    "- **Problem**: What is $p_y(y)$? \n",
    "\n",
    "- **Solution**: Note that $h(x)$ is invertible with $x = g(y) = \\sigma y + \\mu$. The change-of-variable formula leads to\n",
    "$$\\begin{align*}\n",
    "p_y(y) &= p_x(g(y)) \\cdot g^\\prime(y) \\\\\n",
    "  &= p_x(\\sigma y + \\mu) \\cdot \\sigma \\\\\n",
    "  &= \\frac{1}{\\sigma\\sqrt(2 \\pi)} \\exp\\left( - \\frac{(\\sigma y + \\mu - \\mu)^2}{2\\sigma^2}\\right) \\cdot \\sigma \\\\\n",
    "  &=  \\frac{1}{\\sqrt(2 \\pi)} \\exp\\left( - \\frac{y^2 }{2}\\right)\\\\\n",
    "  &= \\mathcal{N}(y|0,1) \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Probabilities should be interpretated as degrees of belief, i.e., a state-of-knowledge, rather than a property of nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can do everything with only the **sum rule** and the **product rule**. In practice, **Bayes rule** and **marginalization** are often very useful for inference, i.e., for computing\n",
    "\n",
    "$$p(\\,\\text{what-we-want-to-know}\\,|\\,\\text{what-we-already-know}\\,)\\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Bayes rule $$ p(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)} {p(D)} $$ is the fundamental rule for learning from data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For a variable $X$ with distribution $p(X)$ with mean $\\mu_x$ and variance $\\Sigma_x$, the mean and variance of the **Linear Transformation** $Z = AX +b$ is given by \n",
    "$$\\begin{align}\n",
    "\\mu_z &= A\\mu_x + b \\tag{SRG-3a}\\\\\n",
    "\\Sigma_z &= A\\,\\Sigma_x\\,A^T \\tag{SRG-3b}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- That's really about all you need to know about probability theory, but you need to _really_ know it, so do the [Exercises](https://nbviewer.org/github/bertdv/BMLIP/blob/master/lessons/exercises/Exercises-Probability-Theory-Review.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\n",
       "This HTML file contains custom styles and some javascript.\n",
       "Include it a Jupyter notebook for improved rendering.\n",
       "-->\n",
       "\n",
       "<!-- Fonts -->\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<!-- Custom style -->\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: rgb(245,245,245);\n",
       "}\n",
       "\n",
       "div.container {\n",
       "    min-width: 960px;\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    margin: auto;\n",
       "    padding-left: 0em;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "    margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running {\n",
       "    border: 1px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\n",
       "div.cell.code_cell {\n",
       "    background-color: rgb(256,256,256);\n",
       "    border-radius: 0px;\n",
       "    padding: 0.5em;\n",
       "    margin-left:1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Alegreya Sans' sans-serif;\n",
       "    line-height: 140%;\n",
       "    font-size: 125%;\n",
       "    font-weight: 400;\n",
       "    width:800px;\n",
       "    margin-left:auto;\n",
       "    margin-right:auto;\n",
       "}\n",
       "\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-style:regular;\n",
       "    font-weight: 400;\n",
       "    font-size: 45pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.3em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    margin-top:16px;\n",
       "    font-size: 22pt;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: regular;\n",
       "    color: rgb(102,102,0);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {    /*Use this for captions*/\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-size: 14pt;\n",
       "    text-align: center;\n",
       "    margin-top: 0em;\n",
       "    margin-bottom: 2em;\n",
       "    font-style: regular;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\n",
       "    font-family: 'Nixie One', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 16pt;\n",
       "    color: rgb(163,0,0);\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.8em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 { /*use this for copyright note*/\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 9pt;\n",
       "    line-height: 100%;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 90%;\n",
       "}\n",
       "\n",
       ".boxed { /* draw a border around a piece of text */\n",
       "  border: 1px solid blue ;\n",
       "}\n",
       "\n",
       "h4#CODE-EXAMPLE,\n",
       "h4#END-OF-CODE-EXAMPLE {\n",
       "    margin: 10px 0;\n",
       "    padding: 10px;\n",
       "    background-color: #d0f9ca !important;\n",
       "    border-top: #849f81 1px solid;\n",
       "    border-bottom: #849f81 1px solid;\n",
       "}\n",
       "\n",
       ".emphasis {\n",
       "    color: red;\n",
       "}\n",
       "\n",
       ".exercise {\n",
       "    color: green;\n",
       "}\n",
       "\n",
       ".proof {\n",
       "    color: blue;\n",
       "}\n",
       "\n",
       "code {\n",
       "  padding: 2px 4px !important;\n",
       "  font-size: 90% !important;\n",
       "  color: #222 !important;\n",
       "  background-color: #efefef !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\n",
       "   as they will be removed through some other method */\n",
       "@media not print {\n",
       "  .cell:nth-last-child(-n+2) {\n",
       "    display: none;\n",
       "  }\n",
       "}\n",
       "\n",
       "footer.hidden-print {\n",
       "    display: none !important;\n",
       "}\n",
       "    \n",
       "</style>\n",
       "\n",
       "<!-- MathJax styling -->\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        CommonHTML: {\n",
       "                            scale: 200\n",
       "                        },\n",
       "                TeX: {\n",
       "                    extensions: [\"AMSmath.js\"],\n",
       "                    equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\n",
       "                },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f\n",
    "    display(\"text/html\", read(f,String))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "widgets": {
   "state": {
    "0c9c7079-a918-4ed4-ad45-8de3d7874019": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "261fa34c-df0a-4604-a2ff-35a9cb4d9fb2": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "42bb27af-6a2c-4a24-bcd3-1d8b8aec035c": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "50e83b63-be9e-4e83-987a-8b3ee9bbabd6": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "8053293d-ebc1-46b4-ac1c-afeb3a53d190": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "f496660b-92e4-41a4-a67b-b3ca19795f03": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
