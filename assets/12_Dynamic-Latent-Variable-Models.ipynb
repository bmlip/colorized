{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic Latent Variable Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Introduction to dynamic (=temporal) Latent Variable Models, including the Hidden Markov Model and Kalman filter.   \n",
    "- Materials\n",
    "  - Mandatory\n",
    "    - These lecture notes\n",
    "  - Optional \n",
    "    - Bishop pp.605-615 on Hidden Markov Models\n",
    "    - Bishop pp.635-641 on Kalman filters\n",
    "    - Faragher (2012), [Understanding the Basis of the Kalman Filter](./files/Faragher-2012-Understanding-the-Basis-of-the-Kalman-Filter.pdf)\n",
    "    - Minka (1999), [From Hidden Markov Models to Linear Dynamical Systems](./files/Minka-1999-from-HMM-to-LDS.pdf)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Problem\n",
    "\n",
    "- <span class=\"exercise\">We consider a one-dimensional cart position tracking problem, see</span>  [Faragher 2012](./files/Faragher-2012-Understanding-the-Basis-of-the-Kalman-Filter.pdf).  \n",
    "\n",
    "- <span class=\"exercise\">The hidden states are the position $z_t$ and velocity $\\dot z_t$. We can apply an external acceleration/breaking force $u_t$. (Noisy) observations are represented by $x_t$.</span> \n",
    "\n",
    "- <span class=\"exercise\">The equations of motions are given by</span>\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\begin{bmatrix} z_t \\\\ \\dot{z_t}\\end{bmatrix} &=  \\begin{bmatrix} 1 & \\Delta t \\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix} z_{t-1} \\\\ \\dot z_{t-1}\\end{bmatrix} + \\begin{bmatrix} (\\Delta t)^2/2 \\\\ \\Delta t\\end{bmatrix} u_t + \\mathcal{N}(0,\\Sigma_z) \\\\\n",
    "x_t &= \\begin{bmatrix} z_t \\\\ \\dot{z_t}\\end{bmatrix} + \\mathcal{N}(0,\\Sigma_x) \n",
    "\\end{align*}$$\n",
    "\n",
    "- <span class=\"exercise\">Infer the position after 10 time steps.</span> \n",
    "\n",
    "<img src=\"./figures/Faragher-2012-cart-1.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dynamical Models\n",
    "\n",
    "<!--- - In this lesson, we consider models where the sequence order of observations matters. \n",
    "--->\n",
    "\n",
    "- Consider the _ordered_ observation sequence $x^T \\triangleq \\left(x_1,x_2,\\ldots,x_T\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We wish to develop a generative model\n",
    "    $$ p( x^T \\,|\\, \\theta)$$\n",
    "that 'explains' the time series $x^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We cannot use the IID assumption $p( x^T  | \\theta) = \\prod_t p(x_t \\,|\\, \\theta)$. In general, we _can_ use the [**chain rule**](https://en.wikipedia.org/wiki/Chain_rule_(probability) (a.k.a. the general product rule)\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(x^T) &= p(x_T|x^{T-1}) \\,p(x^{T-1}) \\\\\n",
    "  &=  p(x_T|x^{T-1}) \\,p(x_{T-1}|x^{T-2}) \\cdots p(x_2|x_1)\\,p(x_1) \\\\\n",
    "  &= p(x_1)\\prod_{t=2}^T p(x_t\\,|\\,x^{t-1})\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generally, we will want to limit the depth of dependencies on previous observations. For example, the $M$th-order linear **Auto-Regressive** (AR) model\n",
    "    $$\\begin{align*}\n",
    "  p(x_t\\,|\\,x^{t-1}) = \\mathcal{N}\\left(x_t \\,\\middle|\\,  \\sum_{m=1}^M a_m x_{t-m}\\,,\\sigma^2\\,\\right)  \n",
    "    \\end{align*}$$\n",
    "    limits the dependencies to the past $M$ samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### State-space Models\n",
    "\n",
    "- A limitation of AR models is that they need a lot of parameters in order to create a flexible model. E.g., if $x_t$ is an $K$-dimensional discrete variable, then an $M$th-order AR model will have $K^{M-1}(K-1)$ parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Similar to our work on Gaussian Mixture models and latent Factor models, we can create a flexible dynamic system by introducing _latent_ (unobserved) variables  $z^T \\triangleq \\left(z_1,z_2,\\dots,z_T\\right)$ (one $z_t$ for each observation $x_t$). In dynamic systems, the latent variables $z_t$ are usually called _state variables_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A general **state space model** is defined by\n",
    "$$\\begin{align*}\n",
    " p(x^T,z^T) &= \\underbrace{p(z_1)}_{\\text{initial state}} \\prod_{t=2}^T \\underbrace{p(z_t\\,|\\,z^{t-1})}_{\\text{state transitions}}\\,\\prod_{t=1}^T \\underbrace{p(x_t\\,|\\,z_t)}_{\\text{observations}}\n",
    "\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A very common computational assumption is to let state transitions be ruled by a _first-order Markov chain_ as\n",
    "$$\n",
    " p(z_t\\,|\\,z^{t-1}) = p(z_t\\,|\\,z_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- <span class=\"exercise\">Exercise: Show that in a Markovian state-space model, the observation sequence $x^T$ is not a first-order Markov chain, i.e., show that for the model\n",
    "    $$\\begin{align*}\n",
    " p(x^T,z^T) &= p(z_1) \\prod_{t=2}^T p(z_t\\,|\\,z_{t-1})\\,\\prod_{t=1}^T p(x_t\\,|\\,z_t)\n",
    "\\end{align*}$$\n",
    "the following statement holds: \n",
    "    $$p(x_t\\,|\\,x_{t-1},x_{t-2}) \\neq p(x_t\\,|\\,x_{t-1})\\,.$$\n",
    "In other words, the latent variables $z_t$ represent a memory bank for past observations beyond $t-1$. \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hidden Markov Models and Linear Dynamical Systems\n",
    "\n",
    "- A **Hidden Markov Model** (HMM) is a specific state-space model with <span class=\"emphasis\">discrete-valued</span> state variables $Z_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- E.g., $Z_t$ is a $K$-dimensional hidden binary 'class indicator' with transition probabilities $A_{jk} \\triangleq p(z_{tk}=1\\,|\\,z_{t-1,j}=1)$, or equivalently\n",
    "  $$p(z_t|z_{t-1}) = \\prod_{k=1}^K \\prod_{j=1}^K A_{jk}^{z_{t-1,j}z_{tk}}$$\n",
    "which is usually accompanied by an initial state distribution $\\pi_k \\triangleq p(z_{1k}=1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  \n",
    "- The classical HMM has also discrete-valued observations but in pratice any (probabilistic) observation model $p(x_t|z_t)$ may be coupled to the hidden Markov chain. \n",
    "\n",
    "<!---\n",
    "- The following figure shows the typical trellis structure of the many possible state transitions paths.   \n",
    "<img src=\"./figures/Figure13.7.png\" width=\"400px\">\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another well-known state-space model with <span class=\"emphasis\">continuous-valued</span> state variables $Z_t$ is the **(Linear) Gaussian Dynamical System** (LGDS), which is defined as\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(z_t\\,|\\,z_{t-1}) &= \\mathcal{N}\\left(\\, A z_{t-1}\\,,\\,\\Sigma_z\\,\\right) \\\\ \n",
    "p(x_t\\,|\\,z_t) &= \\mathcal{N}\\left(\\, C z_t\\,,\\,\\Sigma_x\\,\\right) \\\\\n",
    "p(z_1) &= \\mathcal{N}\\left(\\, \\mu_1\\,,\\,\\Sigma_1\\,\\right)\n",
    "\\end{align*}$$\n",
    "<!---or, equivalently (in the usual state-space notation)\n",
    "$$\\begin{align*}\n",
    "z_k &= A z_{k-1} + \\mathcal{N}\\left(0,\\Sigma_z \\right) \\\\ \n",
    "x_k &= C z_k + \\mathcal{N}\\left( 0, \\Sigma_x \\right) \\\\\n",
    "z_1 &= \\mu_1 + \\mathcal{N}\\left( 0, \\Sigma_1\\right)\n",
    "\\end{align*}$$\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Note that the joint distribution over $\\{(x_1,z_1),\\ldots,(x_t,z_t)\\}$ is a (large-dimensional) Gaussian distribution. This means that, in principle, every inference problem on the LGDS model also leads to a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- HMM's and LGDS's (and variants thereof) are at the basis of a wide range of complex information processing systems, such as speech and language recognition, robotics and automatic car navigation, and even processing of DNA sequences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kalman Filtering\n",
    "\n",
    "- Technically, a [**Kalman filter**](https://en.wikipedia.org/wiki/Kalman_filter) is the solution to the recursive estimation (inference) of the hidden state $z_t$ based on past observations in an LGDS, i.e., Kalman filtering solves the problem $p(z_t\\,|\\,x^t)$ based on the previous estimate $p(z_{t-1}\\,|\\,x^{t-1})$ and a new observation $x_t$ (in the context of the given model specification of course). \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    "- Let's infer the Kalman filter for a scalar linear Gaussian dynamical system:\n",
    "$$\\begin{align*}\n",
    "    p(z_t\\,|\\,z_{t-1}) &= \\mathcal{N}(z_t\\,|\\,a z_{t-1},\\sigma_z^2) \\tag{state transition}   \\\\\n",
    "    p(x_t\\,|\\,z_t) &= \\mathcal{N}(x_t\\,|\\,c z_t,\\sigma_x^2) \\tag{observation}     \n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "        \n",
    "- Kalman filtering comprises inferring $p(z_t\\,|\\,x^t)$ from a given prior estimate $p(z_{t-1}\\,|\\,x^{t-1})$ and a new observation $x_t$. Let us assume that \n",
    "$$\\begin{align} \n",
    "p(z_{t-1}\\,|\\,x^{t-1}) = \\mathcal{N}(z_{t-1} \\,|\\, \\mu_{t-1}, \\sigma_{t-1}^2) \\tag{prior}\n",
    "\\end{align}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Note that everything is Gaussian, so this is _in principle_ possible to execute inference problems analytically and the result will be a Gaussian posterior:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\underbrace{p(z_t\\,|\\,x^t)}_{\\text{posterior}} &= p(z_t\\,|\\,x_t,x^{t-1}) \\propto p(x_t,z_t\\,|\\,x^{t-1}) \\\\\n",
    "  &\\propto p(x_t\\,|\\,z_t) \\,p(z_t\\,|\\,x^{t-1}) \\\\\n",
    "  &= p(x_t\\,|\\,z_t) \\, \\sum_{z_{t-1}} p(z_t,z_{t-1}\\,|\\,x^{t-1}) \\\\\n",
    "  &= \\underbrace{p(x_t\\,|\\,z_t)}_{\\text{observation}} \\, \\sum_{z_{t-1}} \\underbrace{p(z_t\\,|\\,z_{t-1})}_{\\text{state transition}} \\, \\underbrace{p(z_{t-1}\\,|\\,x^{t-1})}_{\\text{prior}} \\\\\n",
    "  &= \\mathcal{N}(x_t\\,|\\,c z_t,\\sigma_x^2) \\sum_{z_{t-1}} \\mathcal{N}(z_t\\,|\\,a z_{t-1},\\sigma_z^2) \\, \\mathcal{N}(z_{t-1} \\,|\\, \\mu_{t-1}, \\sigma_{t-1}^2) \\\\\n",
    "  &\\propto \\mathcal{N}\\left(z_t\\,\\bigm| \\,\\frac{x_t}{c} ,\\left(\\frac{\\sigma_x}{c}\\right)^2\\right) \\times \\mathcal{N}\\left(z_t\\, \\bigm|\\,a \\mu_{t-1},\\sigma_z^2 + \\left(a \\sigma_{t-1}\\right)^2 \\right) \\\\\n",
    "  &= \\mathcal{N}\\left( z_t \\,|\\, \\mu_t, \\sigma_t^2\\right)\n",
    "\\end{align*}$$\n",
    "with\n",
    "$$\\begin{align*}\n",
    "  \\rho_t^2 &= \\sigma_z^2 + a^2 \\sigma_{t-1}^2 \\tag{auxiliary variable}\\\\\n",
    "  K_t &= \\frac{c \\rho_t^2}{c^2 \\rho_t^2 + \\sigma_x^2} \\tag{'Kalman gain'} \\\\\n",
    "  \\mu_t &= a \\mu_{t-1} + K_t \\cdot \\left( x_t - c a \\mu_{t-1}\\right) \\tag{posterior mean}\\\\\n",
    "  \\sigma_t^2 &= \\left( 1 - K_t \\right) \\rho_t^2 \\tag{posterior variance}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Kalman filtering consists of computing/updating these four equations for each new observation ($x_t$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Problem Revisited\n",
    "\n",
    "We can solve the cart tracking problem by a Kalman filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "INsert a picture here similar to lesson 13 that demostrates the result of Kalman filter-based estimation of the position after 10 time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap Dynamical Models \n",
    "\n",
    "- In short, it is possible to analytically derive the Kalman filter for a linear dynamical system with Gaussian state and observation noise (eventhough it is not a fun exercise). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If anything changes in the model, e.g., the state noise is not Gaussian, then you have to re-derive the inference equations again from scratch and it may not lead to an analytically pleasing answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\Rightarrow$ Generally, we will want to automate the inference process. This issue is discussed in the next lesson on inference by message passing in factor graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extensions of Generative Gaussian Models\n",
    "<img src=\"./figures/fig-generative-Gaussian-models.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\n",
       "This HTML file contains custom styles and some javascript.\n",
       "Include it a Jupyter notebook for improved rendering.\n",
       "-->\n",
       "\n",
       "<!-- Fonts -->\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<!-- Custom style -->\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: rgb(245,245,245);\n",
       "}\n",
       "\n",
       "div.container {\n",
       "    min-width: 960px;\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    margin: auto;\n",
       "    padding-left: 0em;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "    margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running {\n",
       "    border: 1px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\n",
       "div.cell.code_cell {\n",
       "    background-color: rgb(256,256,256);\n",
       "    border-radius: 0px;\n",
       "    padding: 0.5em;\n",
       "    margin-left:1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Alegreya Sans' sans-serif;\n",
       "    line-height: 140%;\n",
       "    font-size: 125%;\n",
       "    font-weight: 400;\n",
       "    width:800px;\n",
       "    margin-left:auto;\n",
       "    margin-right:auto;\n",
       "}\n",
       "\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-style:regular;\n",
       "    font-weight: 400;\n",
       "    font-size: 45pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.3em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    margin-top:16px;\n",
       "    font-size: 22pt;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: regular;\n",
       "    color: rgb(102,102,0);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {    /*Use this for captions*/\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-size: 14pt;\n",
       "    text-align: center;\n",
       "    margin-top: 0em;\n",
       "    margin-bottom: 2em;\n",
       "    font-style: regular;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\n",
       "    font-family: 'Nixie One', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 16pt;\n",
       "    color: rgb(163,0,0);\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.8em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 { /*use this for copyright note*/\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 9pt;\n",
       "    line-height: 100%;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 90%;\n",
       "}\n",
       "\n",
       ".boxed { /* draw a border around a piece of text */\n",
       "  border: 1px solid blue ;\n",
       "}\n",
       "\n",
       "h4#CODE-EXAMPLE,\n",
       "h4#END-OF-CODE-EXAMPLE {\n",
       "    margin: 10px 0;\n",
       "    padding: 10px;\n",
       "    background-color: #d0f9ca !important;\n",
       "    border-top: #849f81 1px solid;\n",
       "    border-bottom: #849f81 1px solid;\n",
       "}\n",
       "\n",
       ".emphasis {\n",
       "    color: red;\n",
       "}\n",
       "\n",
       ".exercise {\n",
       "    color: green;\n",
       "}\n",
       "\n",
       ".proof {\n",
       "    color: blue;\n",
       "}\n",
       "\n",
       "code {\n",
       "  padding: 2px 4px !important;\n",
       "  font-size: 90% !important;\n",
       "  color: #222 !important;\n",
       "  background-color: #efefef !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\n",
       "   as they will be removed through some other method */\n",
       "@media not print {\n",
       "  .cell:nth-last-child(-n+2) {\n",
       "    display: none;\n",
       "  }\n",
       "}\n",
       "\n",
       "footer.hidden-print {\n",
       "    display: none !important;\n",
       "}\n",
       "    \n",
       "</style>\n",
       "\n",
       "<!-- MathJax styling -->\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"],\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f display(\"text/html\", read(f, String)) end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
